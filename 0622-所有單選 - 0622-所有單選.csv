question_id,question_content,A,B,C,D,true_answer,detail_explain,expert_common
1,"A Security Engineer has discovered that, although encryption was enabled on the Amazon S3 bucket example bucket, anyone who has access to the bucket has the ability to retrieve the files. The Engineer wants to limit access to each IAM user can access an assigned folder only. What should the Security Engineer do to achieve this?",(A) Use envelope encryption with the AWS-managed CMK aws/s3.,"(B) Create a customer-managed CMK with a key policy granting ""kms:Decrypt"" based on the ""
{aws:username}"" variable.",(C) Create a customer-managed CMK for each user. Add each user as a key user in their corresponding key policy.,"(D) Change the applicable IAM policy to grant S3 access to ""Resource"": ""arn:aws:s3:::examplebucket/
{aws:username}/*""",D,,
4,A windows machine in one VPC needs to join the AD domain in another VPC. VPC Peering has been established. But the domain join is not working. What is the other step that needs to be followed to ensure that the AD domain join can work as intended Please select:,(A) Change the VPC peering connection to a VPN connection,(B) Change the VPC peering connection to a Direct Connect connection,(C) Ensure the security groups for the AD hosted subnet has the right rule for relevant subnets,(D) Ensure that the AD is placed in a public subnet,C,"In addition to VPC peering and setting the right route tables, the security groups for the AD EC2 instance needs to ensure the right rules are put in place for allowing incoming traffic. Option A and B is invalid because changing the connection type will not help. This is a problem with the Security Groups. Option D is invalid since the AD should not be placed in a public subnet For more information on allowing ingress traffic for AD, please visit the following url|https://docs.aws.amazon.com/quickstart/latest/active-directory-ds/ingress.html|  The correctanswer is: Ensure the security groups for the AD hosted subnet has the right rule for relevant subnets Submit your Feedback/Queries to our Experts",
5,Which approach will generate automated security alerts should too many unauthorized AWS API requests be identified?,(A) Create an Amazon CloudWatch metric filter that looks for API call error codes and then implement an alarm based on that metric's rate.,(B) Configure AWS CloudTrail to stream event data to Amazon Kinesis. Configure an AWS Lambda function on the stream to alarm when the threshold has been exceeded.,(C) Run an Amazon Athena SQL query against CloudTrail log files. Use Amazon QuickSight to create an operational dashboard.,"(D) Use the Amazon Personal Health Dashboard to monitor the account's use of AWS services, and raise an alert if service error rates increase.",A,"https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudwatch-alarms-for-cloudtrail.html#cloudwatch- Open the CloudWatch console at  https://console.aws.amazon.com/cloudwatch/. In the navigation pane, choose Logs. In the list of loggroups, select the check box next to the log group that you created for CloudTrail log events. ChooseCreate Metric Filter. On the Define Logs Metric Filter screen, choose Filter Pattern and then type thefollowing: { (.errorCode = ""*UnauthorizedOperation"") || (.errorCode = ""AccessDenied*"") } ChooseAssign Metric. For Filter Name, type AuthorizationFailures. For Metric Namespace, typeCloudTrailMetrics.For Metric Name, type AuthorizationFailureCount.",
9,A Security Engineer discovers that developers have been adding rules to security groups that allow SSH and RDP traffic from 0.0.0.0/0 instead of the organization firewall IP. What is the most efficient way to remediate the risk of this activity?,(A) Delete the internet gateway associated with the VPC.,(B) Use network access control lists to block source IP addresses matching 0.0.0.0/0.,(C) Use a host-based firewall to prevent access from all but the organization's firewall IP.,(D) Use AWS Config rules to detect 0.0.0.0/0 and invoke an AWS Lambda function to update the security group with the organization's firewall IP.,D,,
10,You want to launch an EC2 Instance with your own key pair in AWS. How can you achieve this? Choose 1 answers from options can not do this. Please select:,(A) Use a third party tool to create the Key pair,(B) Create a new key pair using the AWS CLI,(C) Import the public key into EC2,(D) Import the private key into EC2,D,"This is given in the AWS Documentation Creating a Key PairYou can use Amazon EC2 to create your key pair. For more information, see Creating a Key Pair UsingAmazon EC2.Alternatively, you could use a third-party tool and then import the public key to Amazon EC2. Formore information, see Importing Your Own Public Key to Amazon EC2.Option B is Correct, because you can use the AWS CLI to create a new key pair 1https://docs.aws.amazon.com/cli/latest/userguide/cli-ec2-keypairs.htmlOption D is invalid because the public key needs to be stored in the EC2 Instance For moreinformation on EC2 Key pairs, please visit the below URL:* https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairsThe correct answers are: Use a third party tool to create the Key pair. Create a new key pair using theAWS CLI, Import the public key into EC2 Submit your Feedback/Queries to our Experts",
11,"Development teams in your organization use S3 buckets to store the log files for various applications hosted ir development environments in AWS. The developers want to keep the logs for one month for troubleshooting purposes, and then purge the logs. What feature will enable this requirement? Please select:",(A) Adding a bucket policy on the S3 bucket.,(B) Configuring lifecycle configuration rules on the S3 bucket.,(C) Creating an IAM policy for the S3 bucket.,(D) Enabling CORS on the S3 bucket.,B,"The AWS Documentation mentions the following on lifecycle policiesLifecycle configuration enables you to specify the lifecycle management of objects in a bucket. Theconfiguration is a set of one or more rules, where each rule defines an action for Amazon S3 to applyto a group of objects. These actions can be classified as follows:Transition actions - In which you define when objects transition to another . For example, you maychoose to transition objects to the STANDARDJA (IA, for infrequent access) storage class 30 days aftercreation, or archive objects to the GLACIER storage class one year after creation.Expiration actions - In which you specify when the objects expire. Then Amazon S3 deletes the expiredobjects on your behalf.Option A and C are invalid because neither bucket policies neither 1AM policy's can control thepurging of logs Option D is invalid CORS is used for accessing objects across domains and not forpurging of logs For more information on AWS S3 Lifecycle policies, please visit the following URL:com/AmazonS3/latest/d<The correct answer is: Configuring lifecycle configuration rules on the S3 bucket. Submit yourFeedback/Queries to our Experts",
12,"In order to encrypt data in transit for a connection to an AWS RDS instance, which of the following would you implement Please select:",(A) Transparent data encryption,(B) SSL from your application,(C) Data keys from AWS KMS,(D) Data Keys from CloudHSM,B,"This is mentioned in the AWS DocumentationYou can use SSL from your application to encrypt a connection to a DB instance running MySQLMariaDB, Amazon Aurora, SQL Server, Oracle, or PostgreSQL.Option A is incorrect since Transparent data encryption is used for data at rest and not in transitOptions C and D are incorrect since keys can be used for encryption of data at rest For moreinformation on working with RDS and SSL, please refer to below URL:https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.SSL.html The correctanswer is: SSL from your application Submit your Feedback/Queries to our Experts",
13,Your company has just set up a new central server in a VPC. There is a requirement for other teams who have their servers located in different VPC's in the same region to connect to the central server. Which of the below options is best suited to achieve this requirement. Please select:,(A) Set up VPC peering between the central server VPC and each of the teams VPCs.,(B) Set up AWS DirectConnect between the central server VPC and each of the teams VPCs.,(C) Set up an IPSec Tunnel between the central server VPC and each of the teams VPCs.,(D) None of the above options will work.,A,"6A VPC peering connection is a networking connection between two VPCs that enables you to routetraffic between them using private IPv4 addresses or IPv6 addresses. Instances in either VPC cancommunicate with each other as if they are within the same network. You can create a VPC peeringconnection between your own VPCs, or with a VPC in another AWS account within a single region.Options B and C are invalid because you need to use VPC PeeringOption D is invalid because VPC Peering is availableFor more information on VPC Peering please see the below Link:http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-peering.htmlThe correct answer is: Set up VPC peering between the central server VPC and each of the teamsVPCs.Submit your Feedback/Queries to our Experts",
14,How can you ensure that instance in an VPC does not use AWS DNS for routing DNS requests. You want to use your own managed DNS instance. How can this be achieved? Please select:,(A) Change the existing DHCP options set,(B) Create a new DHCP options set and replace the existing one.,(C) Change the route table for the VPC,(D) Change the subnet configuration to allow DNS requests from the new DNS Server,B,"In order to use your own DNS server, you need to ensure that you create a new custom DHCP optionsset with the IP of th custom DNS server. You cannot modify the existing set, so you need to create anew one.Option A is invalid because you cannot make changes to an existing DHCP options Set.Option C is invalid because this can only be used to work with Routes and not with a custom DNSsolution.Option D is invalid because this needs to be done at the VPC level and not at the Subnet level Formore information on DHCP options set, please visit the following urlhttps://docs.aws.amazon.com/AmazonVPC/latest/UserGuideA/PC DHCP Options.html The correctanswer is: Create a new DHCP options set and replace the existing one. Submit yourFeedback/Queries to our Experts",
15,Your company is planning on using bastion hosts for administering the servers in AWS. Which of the following is the best description of a bastion host from a security perspective? Please select:,(A) A Bastion host should be on a private subnet and never a public subnet due to security concerns,(B) A Bastion host sits on the outside of an internal network and is used as a gateway into the private network and is considered the critical strong point of the network,(C) Bastion hosts allow users to log in using RDP or SSH and use that session to SSH into internal network to access private subnet resources.,(D) A Bastion host should maintain extremely tight security and monitoring as it is available to the public,C,"7A bastion host is a special purpose computer on a network specifically designed and configured towithstand attacks. The computer generally hosts a single application, for example a proxy server, andall other services are removed or limited to reduce the threat to the computer.In AWS, A bastion host is kept on a public subnet. Users log on to the bastion host via SSH or RDP andthen use that session to manage other hosts in the private subnets.Options A and B are invalid because the bastion host needs to sit on the public network. Option D isinvalid because bastion hosts are not used for monitoring For more information on bastion hosts, justbrowse to the below URL:https://docsaws.amazon.com/quickstart/latest/linux-bastion/architecture.htl The correct answer is:Bastion hosts allow users to log in using RDP or SSH and use that session to SSH into internal networkto access private subnet resources.Submit your Feedback/Queries to our Experts",
16,"A company has complex connectivity rules governing ingress, egress, and communications between Amazon EC2 instances. The rules are so complex that they cannot be implemented within the limits of the maximum number of security groups and network access control lists (network ACLs). What mechanism will allow the company to implement all required network rules without incurring additional cost?",(A) Configure AWS WAF rules to implement the required rules.,"(B) Use the operating system built-in, host-based firewall to implement the required rules.",(C) Use a NAT gateway to control ingress and egress according to the requirements.,"(D) Launch an EC2-based firewall product from the AWS Marketplace, and implement the required rules in that product.",B,,
17,You are planning to use AWS Config to check the configuration of the resources in your AWS account. You are planning on using an existing IAM role and using it for the AWS Config resource. Which of the following is required to ensure the AWS config service can work as required? Please select:,(A) Ensure that there is a trust policy in place for the AWS Config service within the role,(B) Ensure that there is a grant policy in place for the AWS Config service within the role,(C) Ensure that there is a user policy in place for the AWS Config service within the role,(D) Ensure that there is a group policy in place for the AWS Config service within the role,A,"8 Options B,C and D are invalid because you need to ensure a trust policy is in place and not a grant,user or group policy or more information on the 1AM role permissions please visit the below Link:https://docs.aws.amazon.com/config/latest/developerguide/iamrole-permissions.htmll The correctanswer is: Ensure that there is a trust policy in place for the AWS Config service within the roleSubmit your Feedback/Queries to our Experts",
19,A Security Engineer is trying to determine whether the encryption keys used in an AWS service are in compliance with certain regulatory standards. Which of the following actions should the Engineer perform to get further guidance?,(A) Read the AWS Customer Agreement.,(B) Use AWS Artifact to access AWS compliance reports.,(C) Post the question on the AWS Discussion Forums.,(D) Run AWS Config and evaluate the configuration outputs.,B,https://aws.amazon.com/artifact/,
20,Your company is hosting a set of EC2 Instances in AWS. They want to have the ability to detect if any port scans occur on their AWS EC2 Instances. Which of the following can help in this regard? Please select:,(A) Use AWS inspector to consciously inspect the instances for port scans,(B) Use AWS Trusted Advisor to notify of any malicious port scans,(C) Use AWS Config to notify of any malicious port scans,(D) Use AWS Guard Duty to monitor any malicious port scans,D,"The AWS blogs mention the following to support the use of AWS GuardDuty GuardDuty voraciouslyconsumes multiple data streams, including several threat intelligence feeds, staying aware ofmalicious addresses, devious domains, and more importantly, learning to accurately identifymalicious or unauthorized behavior in your AWS accounts. In combination with information gleanedfrom your VPC Flow Logs, AWS CloudTrail Event Logs, and DNS logs, th allows GuardDuty to detectmany different types of dangerous and mischievous behavior including probes for knownvulnerabilities, port scans and probes, and access from unusual locations. On the AWS side, it looksfor suspicious AWS account activity such as unauthorized deployments, unusual CloudTrail activity,patterns of access to AWS API functions, and attempts to exceed multiple service limits. GuardDutywill also look for compromised EC2 instances talking to malicious entities or services, data exfiltrationattempts, and instances that are mining cryptocurrency.Options A, B and C are invalid because these services cannot be used to detect port scans For moreinformation on AWS Guard Duty, please refer to the below Link:https://aws.amazon.com/blogs/aws/amazon-guardduty-continuous-security-monitoring-threat-detection; ( The correct answer is: Use AWS Guard Duty to monitor any malicious port scans Submityour Feedback/Queries to our Experts10",
22,"You are building a system to distribute confidential training videos to employees. Using CloudFront, what method could be used to serve content that is stored in S3, but not publicly accessible from S3 directly? Please select:",(A) Create an Origin Access Identity (OAI) for CloudFront and grant access to the objects in your S3 bucket to that OAl.,"(B) Add the CloudFront account security group ""amazon-cf/amazon-cf-sg"" to the appropriate S3 bucket policy.",(C) Create an Identity and Access Management (IAM) User for CloudFront and grant access to the objects in your S3 bucket to that IAM User.,(D) Create a S3 bucket policy that lists the CloudFront distribution ID as the Principal and the target bucket as the Amazon Resource Name (ARN).,A,"You can optionally secure the content in your Amazon S3 bucket so users can access it throughCloudFront but cannot access it directly by using Amazon S3 URLs. This prevents anyone frombypassing CloudFront and using the Amazon S3 URL to get content that you want to restrict access to.This step isn't required to use signed URLs, but we recommend it To require that users access yourcontent through CloudFront URLs, you perform the following tasks:Create a special CloudFront user called an origin access identity.Give the origin access identity permission to read the objects in your bucket.Remove permission for anyone else to use Amazon S3 URLs to read the objects.Option B,C and D are all automatically invalid, because the right way is to ensure to create OriginAccess Identity (OAI) for CloudFront and grant access accordingly.For more information on serving private content via Cloudfront, please visit the following URL:https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/PrivateContent.htmll Thecorrect answer is: Create an Origin Access Identity (OAI) for CloudFront and grant access to theobjects in your S3 bucket t that OAI.You can optionally secure the content in your Amazon S3 bucket so users can access it throughCloudFront but cannot access it directly by using Amazon S3 URLs. This prevents anyone frombypassing CloudFront and using the Amazon S3 URL to get content that you want to restrict access to.This step isn't required to use signed URLs, but we recommend it To require that users access yourcontent through CloudFront URLs, you perform the following tasks:Create a special CloudFront user called an origin access identity.Give the origin access identity permission to read the objects in your bucket.Remove permission for anyone else to use Amazon S3 URLs to read the objects.Option B,C and D are all automatically invalid, because the right way is to ensure to create OriginAccess Identity (OAI) for CloudFront and grant access accordingly.For more information on serving private content via Cloudfront, please visit the following URL:https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/PrivateContent.htmll Thecorrect answer is: Create an Origin Access Identity (OAI) for CloudFront and grant access to theobjects in your S3 bucket t that OAI.Submit your Feedback/Queries to our ExpertsSubmit your Feedback/Queries to our Experts",
23,Your company hosts critical data in an S3 bucket. There is a requirement to ensure that all data is encrypted. There is also metadata about the information stored in the bucket that needs to be encrypted aswell. Which of the below measures would you take to ensure that the metadata is encrypted? Please select:,(A) Put the metadata as metadata for each object in the S3 bucket and then enable S3 Server side encryption.,(B) Put the metadata as metadata for each object in the S3 bucket and then enable S3 Server KMS encryption.,(C) Put the metadata in a DynamoDB table and ensure the table is encrypted during creation time.,(D) Put the metadata in the S3 hurkpf itself.,C,"Option A ,B and D are all invalid because the metadata will not be encrypted in any case and this is a12key requirement from the question.One key thing to note is that when the S3 bucket objects are encrypted, the meta data is notencrypted. So the best option is to use an encrypted DynamoDB table Important All GET and PUTrequests for an object protected by AWS KMS will fail if they are not made via SSL or by using SigV4.SSE-KMS encrypts only the object data. Any object metadata is not encrypted. For more informationon using KMS encryption for S3, please refer to below URL: 1https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html The correct answeris: Put the metadata in a DynamoDB table and ensure the table is encrypted during creation time.Submit your Feedback/Queries to our Experts",
24,An application running on EC2 instances in a VPC must access sensitive data in the data center. The access must be encrypted in transit and have consistent low latency. Which hybrid architecture will meet these requirements? Please select:,(A) Expose the data with a public HTTPS endpoint.,(B) A VPN between the VPC and the data center over a Direct Connect connection,(C) A VPN between the VPC and the data center.,(D) A Direct Connect connection between the VPC and data center,B,"Since this is required over a consistency low latency connection, you should use Direct Connect. Forencryption, you can make use of a VPN Option A is invalid because exposing an HTTPS endpoint willnot help all traffic to flow between a VPC and the data center.Option C is invalid because low latency is a key requirementOption D is invalid because only Direct Connect will not sufficeFor more information on the connection options please see the below Link:https://aws.amazon.com/answers/networking/aws-multiple-vpc-vpn-connection-sharint The correctanswer is: A VPN between the VPC and the data center over a Direct Connect connection Submit yourFeedback/Queries to our Experts",
25,"The AWS Systems Manager Parameter Store is being used to store database passwords usedby an AWS Lambda function. Because this is sensitive data, the parameters are stored as type SecureString and protected by an AWS KMS key that allows access through IAM. When the function executes, this parameter cannot be retrieved as the result of an access denied error. Which of the following actions will resolve the access denied error?",(A) Update the ssm.amazonaws.com principal in the KMS key policy to allow kms: Decrypt.,(B) Update the Lambda configuration to launch the function in a VPC.,"(C) Add a policy to the role that the Lambda function uses, allowing kms: Decrypt for the KMS key.",(D) Add lambda.amazonaws.com as a trusted entity on the IAM role that the Lambda function uses.,C,https://docs.amazonaws.cn/en_us/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Integrating.Authorizing.,
26,A Systems Engineer has been tasked with configuring outbound mail through Simple Email Service (SES) and requires compliance with current TLS standards. The mail application should be configured to connect to which of the following endpoints and corresponding ports?,(A) email.us-east-1.amazonaws.com over port 8080,(B) email-pop3.us-east-1.amazonaws.com over port 995,(C) email-smtp.us-east-1.amazonaws.com over port 587,(D) email-imap.us-east-1.amazonaws.com over port 993,C,https://docs.aws.amazon.com/ses/latest/DeveloperGuide/smtp-connect.html,
28,"A company will store sensitive documents in three Amazon S3 buckets based on a data classification scheme of ""Sensitive,"" ""Confidential,"" and ""Restricted."" The security solution must meet all of the following requirements:* Each object must be encrypted using a unique key.* Items that are stored in the ""Restricted"" bucket require two-factor authentication for decryption.* AWS KMS must automatically rotate encryption keys annually. Which of the following meets these requirements?","(A) Create a Customer Master Key (CMK) for each data classification type, and enable the rotation of it annually. For the ""Restricted"" CMK, define the MFA policy within the key policy. Use S3 SSE-KMS to encrypt the objects.",(B) Create a CMK grant for each data classification type with EnableKeyRotation andMultiFactorAuthPresent set to true. S3 can then use the grants to encrypt each object with a uniqueCMK.,"(C) Create a CMK for each data classification type, and within the CMK policy, enable rotation of itannually, and define the MFA policy. S3 can then create DEK grants to uniquely encrypt each objectwithin the S3 bucket.","(D) Create a CMK with unique imported key material for each data classification type, and rotate themannually. For the ""Restricted"" key material, define the MFA policy in the key policy. Use S3 SSE-KMSto encrypt the objects.",A,"CMKs that are not eligible for automatic key rotation, including asymmetric CMKs, CMKs in customkey stores, and CMKs with imported key material.",
29,A company stores data on an Amazon EBS volume attached to an Amazon EC2 instance. The data is asynchronously replicated to an Amazon S3 bucket. Both the EBS volume and the S3 bucket are encrypted with the same AWS KMS Customer Master Key (CMK). A former employee scheduled a deletion of that CMK before leaving the company. The company's Developer Operations department learns about this only after the CMK has been deleted. Which steps must be taken to address this situation?,(A) Copy the data directly from the EBS encrypted volume before the volume is detached from the EC2 instance.,(B) Recover the data from the EBS encrypted volume using an earlier version of the KMS backing key.,(C) Make a request to AWS Support to recover the S3 encrypted data.,"(D) Make a request to AWS Support to restore the deleted CMK, and use it to recover the data.",A,,
30,Your company has an EC2 Instance hosted in AWS. This EC2 Instance hosts an application. Currently this application is experiencing a number of issues. You need to inspect the network packets to see what the type of error that is occurring? Which one of the below steps can help address this issue? Please select:,(A) Use the VPC Flow Logs.,(B) Use a network monitoring tool provided by an AWS partner.,"(C) Use another instance. Setup a port to ""promiscuous mode"" and sniff the traffic to analyze thepackets. -",(D) Use Cloudwatch metric,B,,
31,You want to get a list of vulnerabilities for an EC2 Instance as per the guidelines set by the 15 Center of Internet Security.  How can you go about doing this? Please select:,(A) Enable AWS Guard Duty for the Instance,(B) Use AWS Trusted Advisor,(C) Use AWS inspector,(D) UseAWSMacie,C,"The AWS Inspector service can inspect EC2 Instances based on specific Rules. One of the rulespackages is based on the guidelines set by the Center of Internet Security Center for Internet security(CIS) Benchmarks The CIS Security Benchmarks program provides well-defined, un-biased andconsensus-based industry best practices to help organizations assess and improve their security.Amazon Web Services is a CIS Security Benchmarks Member company and the list of AmazonInspector certifications can be viewed nere.Option A is invalid because this can be used to protect an instance but not give the list ofvulnerabilities Options B and D are invalid because these services cannot give a list of vulnerabilitiesFor more information on the guidelines, please visit the below URL:* https://docs.aws.amazon.com/inspector/latest/userguide/inspector_cis.html The correct answer is:Use AWS Inspector Submit your Feedback/Queries to our Experts",
32,"A company recently experienced a DDoS attack that prevented its web server from serving content. The website is static and hosts only HTML, CSS, and PDF files that users download. Based on the architecture shown in the image, what is the BEST way to protect the site against future attacks while minimizing the ongoing operational overhead?",(A) Move all the files to an Amazon S3 bucket. Have the web server serve the files from the S3 bucket.,(B) Launch a second Amazon EC2 instance in a new subnet. Launch an Application Load Balancer infront of both instances.,(C) Launch an Application Load Balancer in front of the EC2 instance. Create an Amazon CloudFrontdistribution in front of the Application Load Balancer.,(D) Move all the files to an Amazon S3 bucket. Create a CloudFront distribution in front of the bucketand terminate the web server.,D,https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html,
35,An organization has launched 5 instances: 2 for production and 3 for testing. The organization wants that one particular group of IAM users should only access the test instances and not the production ones. How can the organization set that as a part of the policy? Please select:,(A) Launch the test and production instances in separate regions and allow region wise access to the group,(B) Define the IAM policy which allows access based on the instance ID,(C) Create an IAM policy with a condition which allows access to only small instances,(D) Define the tags on the test and production servers and add a condition to the IAM policy which allows access to specification tags,D,"Tags enable you to categorize your AWS resources in different ways, for example, by purpose, owner,or environment. This is useful when you have many resources of the same type - you can quicklyidentify a specific resource based on the tags you've assigned to it Option A is invalid because this is18not a recommended practices Option B is invalid because this is an overhead to maintain this inpolicies Option C is invalid because the instance type will not resolve the requirement Forinformation on resource tagging, please visit the below URL:http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Usine_Tags.htmllThe correct answer is: Define the tags on the test and production servers and add a condition to the1AM policy which allows access to specific tags Submit your Feedback/Queries to our Experts",
36,"A Solutions Architect is designing a web application that uses Amazon CloudFront, an ElasticLoad Balancing Application Load Balancer, and an Auto Scaling group of Amazon EC2 instances. The load balancer and EC2 instances are in the US West (Oregon) region. It has been decided that encryption in transit is necessary by using a customer-branded domain name from the client to CloudFront and from CloudFront to the load balancer. Assuming that AWS Certificate Manager is used, how many certificates will need to be generated?",(A) One in the US West (Oregon) region and one in the US East (Virginia) region.,(B) Two in the US West (Oregon) region and none in the US East (Virginia) region.,(C) One in the US West (Oregon) region and none in the US East (Virginia) region.,(D) Two in the US East (Virginia) region and none in the US West (Oregon) region.,A,"AWS Region that You Request a Certificate In (for AWS Certificate Manager) If you want to requireHTTPS between viewers and CloudFront, you must change the AWS region to US East (N. Virginia) inthe AWS Certificate Manager console before you request or import a certificate. If you want torequire HTTPS between CloudFront and your origin, and you're using an ELB load balancer as yourorigin, you can request or import a certificate in any region.https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/cnames-and-https-requirements.html",
38,A company has a set of EC2 Instances hosted in AWS. The EC2 Instances have EBS volumes which is used to store critical information. There is a business continuity requirement to ensure high availability for the EBS volumes. How can you achieve this?,(A) Use lifecycle policies for the EBS volumes,(B) Use EBS Snapshots,(C) Use EBS volume replication,(D) Use EBS volume encryption,B,"Data stored in Amazon EBS volumes is redundantly stored in multiple physical locations as part ofnormal operation of those services and at no additional charge. However, Amazon EBS replication isstored within the same availability zone, not across multiple zones; therefore, it is highlyrecommended that you conduct regular snapshots to Amazon S3 for long-term data durability OptionA is invalid because there is no lifecycle policy for EBS volumes Option C is invalid because there is noEBS volume replication Option D is invalid because EBS volume encryption will not ensure businesscontinuity For information on security for Compute Resources, please visit the below URL:https://d1.awsstatic.com/whitepapers/Security/Security_Compute_Services_Whitepaper.pdf",
39,A company is planning to run a number of Admin related scripts using the AWS Lambda service. There is a need to understand if there are any errors encountered when the script run. How can this be accomplished in the most effective manner. Please select:,(A) Use Cloudwatch metrics and logs to watch for errors,(B) Use Cloudtrail to monitor for errors,(C) Use the AWS Config service to monitor for errors,(D) Use the AWS inspector service to monitor for errors,A,"The AWS Documentation mentions the followingAWS Lambda automatically monitors Lambda functions on your behalf, reporting metrics throughAmazon CloudWatch. To help you troubleshoot failures in a function. Lambda logs all requestshandled by your function and also automatically stores logs generated by your code through AmazonCloudWatch Logs.Option B,C and D are all invalid because these services cannot be used to monitor for errors. I Formore information on Monitoring Lambda functions, please visit the following URL:https://docs.aws.amazon.com/lambda/latest/dg/monitorine-functions-loes.htmll The correct answeris: Use Cloudwatch metrics and logs to watch for errors Submit your Feedback/Queries to our Experts",
40,"You have private video content in S3 that you want to serve to subscribed users on the Internet. User IDs, credentials, and subscriptions are stored in an Amazon RDS database. Which configuration will allow you to securely serve private content to your users? Please select:",(A) Generate pre-signed URLs for each user as they request access to protected S3 content,(B) Create an 1AM user for each subscribed user and assign the GetObject permission to each 1AMuser,(C) Create an S3 bucket policy that limits access to your private content to only your subscribedusers'credentials20,(D) Crpafp a Cloud Front Clriein Identity user for vnur suhsrrihprl users and assign the GptOhiprtoprmissinn to this user,A,"All objects and buckets by default are private. The pre-signed URLs are useful if you want youruser/customer to be able upload a specific object to your bucket but you don't require them to haveAWS security credentials or permissions. When you create a pre-signed URL, you must provide yoursecurity credentials, specify a bucket name, an object key, an HTTP method (PUT for uploadingobjects), and an expiration date and time.The pre-signed URLs are valid only for the specified duration.Option B is invalid because this would be too difficult to implement at a user level.Option C is invalid because this is not possibleOption D is invalid because this is used to serve private content via Cloudfront For more informationon pre-signed urls, please refer to the Link:http://docs.aws.amazon.com/AmazonS3/latest/dev/PresienedUrlUploadObiect.htmll The correctanswer is: Generate pre-signed URLs for each user as they request access to protected S3 contentSubmit your Feedback/Queries to our Experts",
41,You have an instance setup in a test environment in AWS. You installed the required application and the promoted the server to a production environment. Your IT Security team has advised that there maybe traffic flowing in from an unknown IP address to port 22. How can this be mitigated immediately? Please select:,(A) Shutdown the instance,(B) Remove the rule for incoming traffic on port 22 for the Security Group,(C) Change the AMI for the instance,(D) Change the Instance type for the instance,B,"In the test environment the security groups might have been opened to all IP addresses for testingpurpose.Always to ensure to remove this rule once all testing is completed.Option A, C and D are all invalid because this would affect the application running on the server. Theeasiest way is just to remove the rule for access on port 22.For more information on authorizing access to an instance, please visit the below URL:https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/authorizing-access-to-an-instance.htmllThe correct answer is: Remove the rule for incoming traffic on port 22 for the Security Group Submityour Feedback/Queries to our Experts",
42,A company had one of its Amazon EC2 key pairs compromised. A Security Engineer must identify which current Linux EC2 instances were deployed and used the compromised key pair. How can this task be accomplished?,"(A) Obtain the list of instances by directly querying Amazon EC2 using: aws ec2 describe-instances --fi1ters""Name=key-name,Values=KEYNAMEHERE"".21","(B) Obtain the fingerprint for the key pair from the AWS Management Console, then search for the fingerprint in the Amazon Inspector logs.",(C) Obtain the output from the EC2 instance metadata using: curl http://169.254.169.254/latest/meta-data/public- keys/0/.,"(D) Obtain the fingerprint for the key pair from the AWS Management Console, then search for the fingerprint in Amazon CloudWatch Logs using: aws logs filter-log-events.",D,,
43,There is a requirement for a company to transfer large amounts of data between AWS and anon-premise location. There is an additional requirement for low latency and high consistency trafficto AWS. Given these requirements how would you design a hybrid architecture? Choose the correctanswer from the options below Please select:,(A) Provision a Direct Connect connection to an AWS region using a Direct Connect partner.,"(B) Create a VPN tunnel for private connectivity, which increases network consistency and reduceslatency.","(C) Create an iPSec tunnel for private connectivity, which increases network consistency and reduceslatency.",(D) Create a VPC peering connection between AWS and the Customer gateway.,A,"AWS Direct Connect makes it easy to establish a dedicated network connection from your premisesto AWS.Using AWS Direct Connect you can establish private connectivity between AWS and your datacenter,office, or colocation environment which in many cases can reduce your network costs, increasebandwidth throughput and provide a more consistent network experience than Internet-basedconnections.Options B and C are invalid because these options will not reduce network latency Options D isinvalid because this is only used to connect 2 VPC's For more information on AWS direct connect, justbrowse to the below URL:https://aws.amazon.com/directconnectThe correct answer is: Provision a Direct Connect connection to an AWS region using a Direct Connectpartner. omit your Feedback/Queries to our Experts",
44,Your company is planning on developing an application in AWS. This is a web based application. The application users will use their facebook or google identities for authentication. You want to have the ability to manage user profiles without having to add extra coding to manage this. Which of the below would assist in this. Please select:,(A) Create an OlDC identity provider in AWS,(B) Create a SAML provider in AWS,(C) Use AWS Cognito to manage the user profiles,(D) Use IAM users to manage the user profiles,C,"22The AWS Documentation mentions the followingOIDC identity providers are entities in 1AM that describe an identity provider (IdP) service thatsupports the OpenID Connect (OIDC) standard. You use an OIDC identity provider when you want toestablish trust between an OlDC-compatible IdP-such as Google, Salesforce, and many others-andyour AWS account This is useful if you are creating a mobile app or web application that requiresaccess to AWS resources, but you don't want to create custom sign-in code or manage your own useridentities Option A is invalid because in the security groups you would not mention this information/Option C is invalid because SAML is used for federated authentication Option D is invalid because youneed to use the OIDC identity provider in AWS For more information on ODIC identity providers,please refer to the below Link:https://docs.aws.amazon.com/IAM/latest/UserGuide/id roles providers create oidc.htmll The correctanswer is: Create an OIDC identity provider in AWS",
45,You need to create a policy and apply it for just an individual user. How could you accomplish this in the right way? Please select:,(A) Add an AWS managed policy for the user,(B) Add a service policy for the user,(C) Add an IAM role for the user,(D) Add an inline policy for the user,D,"Options A and B are incorrect since you need to add an inline policy just for the user Option C isinvalid because you don't assign an 1AM role to a user The AWS Documentation mentions thefollowing An inline policy is a policy that's embedded in a principal entity (a user, group, or role)-thatis, the policy is an inherent part of the principal entity. You can create a policy and embed it in aprincipal entity, either when you create the principal entity or later.For more information on 1AM Access and Inline policies, just browse to the below URL:https://docs.aws.amazon.com/IAM/latest/UserGuide/accessThe correct answer is: Add an inline policy for the user Submit your Feedback/Queries to our Experts",
48,A Security Analyst attempted to trouble shoot the monitoring of suspicious security group changes. The Analyst was told that there is an Amazon CloudWatch alarm in place for these AWS CloudTrail log events. The Analyst tested the monitoring setup by making a configuration change to the security group butdid not receive any alerts. Which of the following trouble shooting steps should the Analyst perform?,(A) Ensure that CloudTrail and S3 bucket access logging is enabled for the Analyst's AWS account.,(B) Verify that a metric filter was created and then mapped to an alarm. Check the alarm notification action.,(C) Check the CloudWatch dashboards to ensure that there is a metric configured with an a ppropriate dimension for security group changes.,(D) Verify that the Analyst's account is mapped to an IAM policy that includes permissions for cloudwatch:GetMetricStatistics and Cloudwatch: ListMetrics.,B,MetricFilter:Type: 'AWS::Logs::MetricFilter'Properties:LogGroupName: ''FilterPattern: >-{ (.eventName = AuthorizeSecurityGroupIngress) || (.eventName =AuthorizeSecurityGroupEgress) || (.eventName =RevokeSecurityGroupIngress) || (.eventName = RevokeSecurityGroupEgress)|| (.eventName = CreateSecurityGroup) || (.eventName =DeleteSecurityGroup) }MetricTransformations:- MetricValue: '1'MetricNamespace: CloudTrailMetricsMetricName: SecurityGroupEventCount,
49,A Security Engineer has been asked to create an automated process to disable IAM user access keys that are more than three months old. Which of the following options should the Security Engineer use?,"(A) In the AWS Console, choose the IAM service and select ""Users"". Review the ""Access Key Age""column.",(B) Define an IAM policy that denies access if the key age is more than three months and apply to allusers.,"(C) Write a script that uses the GenerateCredentialReport, GetCredentialReport, and UpdateAccessKey APIs.",(D) Create an Amazon CloudWatch alarm to detect aged access keys and use an AWS Lambda functionto disable the keys older than 90 days.,C,https://docs.aws.amazon.com/IAM/latest/APIReference/API_UpdateAccessKey.htmlhttps://docs.aws.amazon.com/IAM/latest/APIReference/API_GenerateCredentialReport.htmlhttps://docs.aws.amazon.com/IAM/latest/APIReference/API_GetCredentialReport.html,
51,The Security team believes that a former employee may have gained unauthorized access to AWS resources sometime in the past 3 months by using an identified access key. What approach would enable the Security team to find out what the former employee may have done within AWS?,(A) Use the AWS CloudTrail console to search for user activity.,(B) Use the Amazon CloudWatch Logs console to filter CloudTrail data by user.,(C) Use AWS Config to see what actions were taken by the user.,(D) Use Amazon Athena to query CloudTrail logs stored in Amazon S3.,A,You can use CloudTrail to search event history for the last 90 days. You can use CloudWatch queriesto search API history beyond the last 90 days. You can use Athena to query CloudTrail logs over thelast 90 days.https://aws.amazon.com/premiumsupport/knowledge-center/view-iam-history/,
52,A Software Engineer wrote a customized reporting service that will run on a fleet of AmazonEC2 instances. The company security policy states that application logs for the reporting service must be centrally collected. What is the MOST efficient way to meet these requirements?,(A) Write an AWS Lambda function that logs into the EC2 instance to pull the application logs from theEC2 instance and persists them into an Amazon S3 bucket.,"(B) Enable AWS CloudTrail logging for the AWS account, create a new Amazon S3 bucket, and then configure Amazon CloudWatch Logs to receive the application logs from CloudTrail.",(C) Create a simple cron job on the EC2 instances that synchronizes the application logs to an AmazonS3 bucket by using rsync.,"(D) Install the Amazon CloudWatch Logs Agent on the EC2 instances, and configure it to send the application logs to CloudWatch Logs.",D,https://aws.amazon.com/blogs/aws/cloudwatch-log-service/,
53,A Security Administrator is performing a log analysis as a result of a suspected AWS account compromise.The Administrator wants to analyze suspicious AWS CloudTrail log files but is overwhelmed by the volume of audit logs being generated. What approach enables the Administrator to search through the logs MOST efficiently?,"(A) Implement a ""write-only"" CloudTrail event filter to detect any modifications to the AWS account resources.",(B) Configure Amazon Macie to classify and discover sensitive data in the Amazon S3 bucket that contains the CloudTrail audit logs.,(C) Configure Amazon Athena to read from the CloudTrail S3 bucket and query the logs to examine account activities.,(D) Enable Amazon S3 event notifications to trigger an AWS Lambda function that sends an email alarm when there are new CloudTrail API entries.,C,,
55,"A water utility company uses a number of Amazon EC2 instances to manage updates to a fleet of 2,000 Internet of Things (IoT) field devices that monitor water quality. These devices each have unique access credentials. An operational safety policy requires that access to specific credentials is independently auditable. What is the MOST cost-effective way to manage the storage of credentials?",(A) Use AWS Systems Manager to store the credentials as Secure Strings Parameters. Secure by usingan AWS KMS key.,"(B) Use AWS Key Management System to store a master key, which is used to encrypt the credentials. The encrypted credentials are stored in an Amazon RDS instance.",(C) Use AWS Secrets Manager to store the credentials.,(D) Store the credentials in a JSON file on Amazon S3 with server-side encryption.,A,https://docs.aws.amazon.com/systems-manager/latest/userguide/parameter-store-advanced-parameters.html,
59,"The Information Technology department has stopped using Classic Load Balancers and switched to Application Load Balancers to save costs. After the switch, some users on older devices are no longer able to connect to the website. What is causing this situation?",(A) Application Load Balancers do not support older web browsers.,(B) The Perfect Forward Secrecy settings are not configured correctly.,(C) The intermediate certificate is installed within the Application Load Balancer.,(D) The cipher suites on the Application Load Balancers are blocking connections.,D,https://docs.aws.amazon.com/elasticloadbalancing/latest/application/create-https-listener.html,
60,Your CTO is very worried about the security of your AWS account. How best can you prevent hackers from completely hijacking your account? Please select:,(A) Use short but complex password on the root account and any administrators.,(B) Use AWS IAM Geo-Lock and disallow anyone from logging in except for in your city.,"(C) Use MFA on all users and accounts, especially on the root account.",(D) Don't write down or remember the root account password after creating the AWS account.,C,"Multi-factor authentication can add one more layer of security to your AWS account Even when you30go to your Security Credentials dashboard one of the items is to enable MFA on your root accountOption A is invalid because you need to have a good password policy Option B is invalid becausethere is no1AM Geo-Lock Option D is invalid because this is not a recommended practices For more informationon MFA, please visit the below URLhttp://docs.aws.amazon.com/IAM/latest/UserGuide/idcredentials mfa.htmllThe correct answer is: Use MFA on all users and accounts, especially on the root account.Submit your Feedback/Queries to our Experts",
61,"When you enable automatic key rotation for an existing CMK key where the backing key is managed by AWS, after how long is the key rotated? Please select:",(A) After 30 days,(B) After 128 days,(C) After 365 days,(D) After 3 years,D,"The AWS Documentation states the following* AWS managed CM Ks: You cannot manage key rotation for AWS managed CMKs. AWS KMSautomatically rotates AWS managed keys every three years (1095 days).Note: AWS-managed CMKs are rotated every 3yrs, Customer-Managed CMKs are rotated every 365-days from when rotation is enabled.Option A, B, C are invalid because the dettings for automatic key rotation is not changeable.For more information on key rotation please visit the below URLhttps://docs.aws.amazon.com/kms/latest/developereuide/rotate-keys.htmlAWS managed CMKs are CMKs in your account that are created, managed, and used on your behalfby an AWS service that is integrated with AWS KMS. This CMK is unique to your AWS account andregion. Only the service that created the AWS managed CMK can use it You can login to you 1AMdashbaord . Click on ""Encryption Keys"" You will find the list based on the services you are using asfollows:* aws/elasticfilesystem 1 aws/lightsail* aws/s3* aws/rds and many more31Detailed Guide: KMSYou can recognize AWS managed CMKs because their aliases have the format aws/service-name,such as aws/redshift. Typically, a service creates its AWS managed CMK in your account when you setup the service or the first time you use the CMfC The AWS services that integrate with AWS KMS canuse it in many different ways. Some services create AWS managed CMKs in your account. Otherservices require that you specify a customer managed CMK that you have created. And, otherssupport both types of CMKs to allow you the ease of an AWS managed CMK or the control of acustomer-managed CMK Rotation period for CMKs is as follows:* AWS managed CMKs: 1095 days* Customer managed CMKs: 365 daysSince question mentions about ""CMK where backing keys is managed by AWS"", its Amazon(AWS)managed and its rotation period turns out to be 1095 days{every 3 years) For more details, pleasecheck below AWS Docs:https://docs.aws.amazon.com/kms/latest/developerguide/concepts.htmlThe correct answer is: After 3 yearsSubmit your Feedback/Queries to our Experts",
62,A distributed web application is installed across several EC2 instances in public subnets residing in two Availability Zones. Apache logs show several intermittent brute-force attacks from hundreds of IP addresses at the layer 7 level over the past six months. What would be the BEST way to reduce the potential impact of these attacks in the future?,(A) Use custom route tables to prevent malicious traffic from routing to the instances.,(B) Update security groups to deny traffic from the originating source IP addresses.,(C) Use network ACLs.,(D) Install intrusion prevention software (IPS) on each instance.,D,"https://docs.aws.amazon.com/vpc/latest/userguide/amazon-vpc-limits.html NACL has limit 20 (canincrease to maximum 40 rule), and more rule will make more low-latency",
64,"A company's AWS account consists of approximately 300 IAM users. Now there is a mandate that an access change is required for 100 IAM users to have unlimited privileges to S3. As a system administrator, how can you implement this effectively so that there is no need to apply the policy at the individual user level? Please select:",(A) Create a new role and add each user to the IAM role,"(B) Use the IAM groups and add users, based upon their role, to different groups and apply the policy to group",(C) Create a policy and apply it to multiple users using a JSON script,(D) Create an S3 bucket policy with unlimited access which includes each user's AWS account ID,B,"Option A is incorrect since you don't add a user to the 1AM RoleOption C is incorrect since you don't assign multiple users to a policy Option D is incorrect since this isnot an ideal approach An 1AM group is used to collectively manage users who need the same set ofpermissions. By having groups, it becomes easier to manage permissions. So if you change thepermissions on the group scale, it will affect all the users in that group For more information on 1AMGroups, just browse to the below URL:https://docs.aws.amazon.com/IAM/latest/UserGuide/id_eroups.htmlThe correct answer is: Use the 1AM groups and add users, based upon their role, to different groupsand apply the policy to group Submit your Feedback/Queries to our Experts",
65,Your development team has started using AWS resources for development purposes. The AWS account has just been created. Your IT Security team is worried about possible leakage of AWS keys. What is the first level of measure that should be taken to protect the AWS account. Please select:,(A) Delete the AWS keys for the root account,(B) Create IAM Groups,(C) Create IAM Roles,(D) Restrict access using 1AM policies,A,"The first level or measure that should be taken is to delete the keys for the 1AM root user When youlog into your account and go to your Security Access dashboard, this is the first step that can be seen33Option B and C are wrong because creation of 1AM groups and roles will not change the impact ofleakage of AWS root access keys Option D is wrong because the first key aspect is to protect theaccess keys for the root account For more information on best practises for Security Access keys,please visit the below URL:https://docs.aws.amazon.com/eeneral/latest/gr/aws-access-keys-best-practices.htmlThe correct answer is: Delete the AWS keys for the root account Submit your Feedback/Queries toour Experts",
68,You want to track access requests for a particular S3 bucket. How can you achieve this in the easiest possible way? Please select:,(A) Enable server access logging for the bucket,(B) Enable Cloudwatch metrics for the bucket,(C) Enable Cloudwatch logs for the bucket,(D) Enable AWS Config for the S3 bucket,A,"The AWS Documentation mentions the foilTo track requests for access to your bucket you can enable access logging. Each access log recordprovides details about a single access request, such as the requester, bucket name, request time,request action, response status, and error code, if any.Options B and C are incorrect Cloudwatch is used for metrics and logging and cannot be used to trackaccess requests.Option D is incorrect since this can be used for Configuration management but for not for tracking S3bucket requests.For more information on S3 server logs, please refer to below UFhttps://docs.aws.amazon.com/AmazonS3/latest/dev/ServerLoes.htmlThe correct answer is: Enable server access logging for the bucket Submit your Feedback/Queries toour Experts",
70,"A Security Administrator at a university is configuring a fleet of Amazon EC2 instances. The EC2 instances are shared among students, and non-root SSH access is allowed. The Administrator is concerned about students attacking other AWS account resources by using the EC2 instance metadata service. What can the Administrator do to protect against this potential attack?",(A) Disable the EC2 instance metadata service.,(B) Log all student SSH interactive session activity.,(C) Implement ip tables-based restrictions on the instances.,(D) Install the Amazon Inspector agent on the instances.36,A,"""To turn off access to instance metadata on an existing instance.....""https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/configuring-instance-metadata-service.html You can disable the service for existing (running or stopped) ec2 instances.https://docs.aws.amazon.com/cli/latest/reference/ec2/modify-instance-metadata-options.html",
71,A Lambda function reads metadata from an S3 object and stores the metadata in a DynamoDB table. The function is triggered whenever an object is stored within the S3 bucket. How should the Lambda function be given access to the DynamoDB table? Please select:,(A) Create a VPC endpoint for DynamoDB within a VPC. Configure the Lambda function to access resources in the VPC.,(B) Create a resource policy that grants the Lambda function permissions to write to the DynamoDB table.Attach the poll to the DynamoDB table.,(C) Create an IAM user with permissions to write to the DynamoDB table. Store an access key for that user in the Lambda environment variables.,(D) Create an IAM service role with permissions to write to the DynamoDB table. Associate that role with the Lambda function.,D,"The ideal way is to create an 1AM role which has the required permissions and then associate it withthe Lambda function The AWS Documentation additionally mentions the following Each Lambdafunction has an 1AM role (execution role) associated with it. You specify the 1AM role when youcreate your Lambda function. Permissions you grant to this role determine what AWS Lambda can dowhen it assumes the role. There are two types of permissions that you grant to the 1AM role:If your Lambda function code accesses other AWS resources, such as to read an object from an S3bucket or write logs to CloudWatch Logs, you need to grant permissions for relevant Amazon S3 andCloudWatch actions to the role.If the event source is stream-based (Amazon Kinesis Data Streams and DynamoDB streams), AWSLambda polls these streams on your behalf. AWS Lambda needs permissions to poll the stream andread new records on the stream so you need to grant the relevant permissions to this role.Option A is invalid because the VPC endpoint allows access instances in a private subnet to accessDynamoDB Option B is invalid because resources policies are present for resources such as S3 andKMS, but not AWS Lambda Option C is invalid because AWS Roles should be used and not 1AM UsersFor more information on the Lambda permission model, please visit the below URL:https://docs.aws.amazon.com/lambda/latest/dg/intro-permission-model.html The correct answer is:Create an 1AM service role with permissions to write to the DynamoDB table.Associate that role with the Lambda function.Submit your Feedback/Queries to our Exp",
72,Every application in a company's portfolio has a separate AWS account for development and production. The security team wants to prevent the root user and all IAM users in the production accounts from accessing a specific set of unneeded services. How can they control this functionality? Please select:,(A) Create a Service Control Policy that denies access to the services. Assemble all production accounts in an organizational unit. Apply the policy to that organizational unit.,(B) Create a Service Control Policy that denies access to the services. Apply the policy to the root account.,(C) Create an IAM policy that denies access to the services. Associate the policy with an IAM group and enlist all users and the root users in this group.,(D) Create an IAM policy that denies access to the services. Create a Config Rule that checks that all users have the policy m assigned. Trigger a Lambda function that adds the policy when found missing.,A,"As an administrator of the master account of an organization, you can restrict which AWS servicesand individual API actions the users and roles in each member account can access. This restrictioneven overrides the administrators of member accounts in the organization. When AWS Organizationsblocks access to a service or API action for a member account a user or role in that account can'taccess any prohibited service or API action, even if an administrator of a member account explicitlygrants such permissions in an 1AM policy.Organization permissions overrule account permissions.Option B is invalid because service policies cannot be assigned to the root account at the accountlevel.Option C and D are invalid because 1AM policies alone at the account level would not be able tosuffice the requirement For more information, please visit the below URL id=docs_orgs_consolehttps://docs.aws.amazon.com/IAM/latest/UserGimanage attach-policy.htmlThe correct answer is: Create a Service Control Policy that denies access to the services. Assemble allproduction accounts in an organizational unit. Apply the policy to that organizational unit Submityour Feedback/Queries to our Experts",
73,Your company has been using AWS for hosting EC2 Instances for their web and databaseapplications. They want to have a compliance check to see the following Whether any ports are leftopen other than admin ones like SSH and RDP Whether any ports to the database server other thanones from the web server security group are open Which of the following can help achieve this in theeasiest way possible. You don't want to carry out an extra configuration changes?Please select:,(A) AWS Config,(B) AWS Trusted Advisor,(C) AWS Inspector,(D) AWSGuardDuty,B,"Trusted Advisor checks for compliance with the following security recommendations:Limited access to common administrative ports to only a small subset of addresses. This includesports 22 (SSH), 23 (Telnet) 3389 (RDP), and 5500 (VNQ.Limited access to common database ports. This includes ports 1433 (MSSQL Server), 1434 (MSSQLMonitor), 3306 (MySQL), Oracle (1521) and 5432 (PostgreSQL).38Option A is partially correct but then you would need to write custom rules for this. The AWS trustedadvisor can give you all o these checks on its dashboard Option C is incorrect. Amazon Inspectorneeds a software agent to be installed on all EC2 instances that are included in th.assessment target, the security of which you want to evaluate with Amazon Inspector. It monitorsthe behavior of the EC2 instance on which it is installed, including network, file system, and processactivity, and collects a wide set of behavior and configuration data (telemetry), which it then passesto the Amazon Inspector service.Our question's requirement is to choose a choice that is easy to implement. Hence Trusted Advisor ismore appropriate for this ) question.Options D is invalid because this service dont provide these details.For more information on the Trusted Advisor, please visit the following URLhttps://aws.amazon.com/premiumsupport/trustedadvisor>The correct answer is: AWS Trusted Advisor Submit your Feedback/Queries to our Experts",
74,Your IT Security team has identified a number of vulnerabilities across critical EC2 Instances inthe company's AWS Account. Which would be the easiest way to ensure these vulnerabilities areremediated?Please select:,(A) Create AWS Lambda functions to download the updates and patch the servers.,(B) Use AWS CLI commands to download the updates and patch the servers.,(C) Use AWS inspector to patch the servers,(D) Use AWS Systems Manager to patch the servers,D,"The AWS Documentation mentions the followingYou can quickly remediate patch and association compliance issues by using Systems Manager RunCommand. You can tat either instance IDs or Amazon EC2 tags and execute the AWS-RefreshAssociation document or the AWS-RunPatchBaseline document. If refreshing the associationor re-running the patch baseline fails to resolve the compliance issue, then you need to investigateyour associations, patch baselines, or instance configurations to understand why the Run Commandexecutions did not resolve the problem Options A and B are invalid because even though this ispossible, still from a maintenance perspective it would be difficult to maintain the Lambda functionsOption C is invalid because this service cannot be used to patch servers For more information onusing Systems Manager for compliance remediation please visit the below Link:https://docs.aws.amazon.com/systems-manaeer/latest/usereuide/sysman-compliance-fixing.htmlThe correct answer is: Use AWS Systems Manager to patch the servers Submit yourFeedback/Queries to our Experts",
75,A Security Engineer is looking for a way to control access to data that is being encryptedunder a CMK. The Engineer is also looking to use additional authenticated data (AAD) to preventtampering with ciphertext.Which action would provide the required functionality?,(A) Pass the key alias to AWS KMS when calling Encrypt and Decrypt API actions.,(B) Use IAM policies to restrict access to Encrypt and Decrypt API actions.,(C) Use kms:EncryptionContext as a condition when defining IAM policies for the CMK.39,(D) Use key policies to restrict access to the appropriate IAM groups.,D,,
77,An EC2 Instance hosts a Java based application that access a DynamoDB table. This EC2 Instance is currently serving production based users. Which of the following is a secure way of ensuring that the EC2 Instance access the Dynamo table Please select:,(A) Use IAM Roles with permissions to interact with DynamoDB and assign it to the EC2 Instance,(B) Use KMS keys with the right permissions to interact with DynamoDB and assign it to the EC2 Instance,(C) Use IAM Access Keys with the right permissions to interact with DynamoDB and assign it to the EC2 Instance,(D) Use IAM Access Groups with the right permissions to interact with DynamoDB and assign it to the EC2  Instance,A,"To always ensure secure access to AWS resources from EC2 Instances, always ensure to assign a Roleto the EC2 Instance Option B is invalid because KMS keys are not used as a mechanism for providingEC2 Instances access to AWS services. Option C is invalid Access keys is not a safe mechanism forproviding EC2 Instances access to AWS services. Option D is invalid because there is no way accessgroups can be assigned to EC2 Instances. For more information on 1AM Roles, please refer to thebelow URL:https://docs.aws.amazon.com/IAM/latest/UserGuide/id roles.htmlThe correct answer is: Use 1AM Roles with permissions to interact with DynamoDB and assign it tothe EC2 Instance Submit your Feedback/Queries to our Experts40",
78,"A company has set up the following structure to ensure that their S3 buckets always have logging enabled If there are any changes to the configuration to an S3 bucket, a config rule gets checked. If logging is disabled, then Lambda function is invoked. This Lambda function will again enable logging on the S3 bucket. Now there is an issue being encoutered with the entire flow. You have verified that the Lambda function is being invoked. But when logging is disabled for the bucket, the lambda function does not enable it again. Which of the following could be an issue Please select:",(A) The AWS Config rule is not configured properly,(B) The AWS Lambda function does not have appropriate permissions for the bucket,(C) The AWS Lambda function should use Node.js instead of python.,(D) You need to also use the API gateway to invoke the lambda function,B,"The most probable cause is that you have not allowed the Lambda functions to have the appropriatepermissions on the S3 bucket to make the relevant changes.Option A is invalid because this is more of a permission instead of a configuration rule issue.Option C is invalid because changing the language will not be the core solution.Option D is invalid because you don't necessarily need to use the API gateway service For moreinformation on accessing resources from a Lambda function, please refer to below URLhttps://docs.aws.amazon.com/lambda/latest/ds/accessing-resources.htmllThe correct answer is: The AWS Lambda function does not have appropriate permissions for thebucket Submit your Feedback/Queries to our Experts",
83,"A company has Windows Amazon EC2 instances in a VPC that are joined to on-premises Active Directory servers for domain services. The security team has enabled Amazon GuardDuty on the AWS account to alert on issues with the instances. During a weekly audit of network traffic, the Security Engineer notices that one of the EC2 instances is attempting to communicate with a known command-and-control server but failing. This alert does not show up in GuardDuty. Why did GuardDuty fail to alert to this behavior?",(A) GuardDuty did not have the appropriate alerts activated.,(B) GuardDuty does not see these DNS requests.,(C) GuardDuty only monitors active network traffic flow for command-and-control activity.,(D) GuardDuty does not report on command-and-control activity.,B,https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_data-sources.htmlhttps://docs.aws.amazon.com/guardduty/latest/ug/guardduty_backdoor.html,
84,"A company has an encrypted Amazon S3 bucket. An Application Developer has an IAM policy that allows access to the S3 bucket, but the Application Developer is unable to access objects within the bucket. What is a possible cause of the issue?",(A) The S3 ACL for the S3 bucket fails to explicitly grant access to the Application Developer,(B) The AWS KMS key for the S3 bucket fails to list the Application Developer as an administrator,(C) The S3 bucket policy fails to explicitly grant access to the Application Developer,(D) The S3 bucket policy explicitly denies access to the Application Developer,C,,
86,"An AWS Lambda function was misused to alter data, and a Security Engineer must identify who invoked the function and what output was produced. The Engineer cannot find any logs created by the Lambda function in Amazon CloudWatch Logs. Which of the following explains why the logs are not available?",(A) The execution role for the Lambda function did not grant permissions to write log data to CloudWatch Logs.,"(B) The Lambda function was executed by using Amazon API Gateway, so the logs are not stored in CloudWatch Logs.",(C) The execution role for the Lambda function did not grant permissions to write to the Amazon S3bucket where CloudWatch Logs stores the logs.,(D) The version of the Lambda function that was executed was not current.,A,,
87,"Your company has confidential documents stored in the simple storage service. Due to compliance requirements, you have to ensure that the data in the S3 bucket is available in a different geographical location. As an architect what is the change you would make to comply with this requirement. Please select:",(A) Apply Multi-AZ for the underlying 53 bucket,(B) Copy the data to an EBS Volume in another Region,(C) Create a snapshot of the S3 bucket and copy it to another region,(D) Enable Cross region replication for the S3 bucket,D,"This is mentioned clearly as a use case for S3 cross-region replication You might configure cross-region replication on a bucket for various reasons, including the following:* Compliance requirements - Although, by default Amazon S3 stores your data across multiplegeographically distant Availability Zones, compliance requirements might dictate that you store dataat even further distances.Cross-region replication allows you to replicate data between distant AWS Regions to satisfy thesecompliance requirements.Option A is invalid because Multi-AZ cannot be used to S3 bucketsOption B is invalid because copying it to an EBS volume is not a recommended practice Option C is46invalid because creating snapshots is not possible in S3 For more information on S3 cross-regionreplication, please visit the following URL:https://docs.aws.amazon.com/AmazonS3/latest/dev/crr.htmllThe correct answer is: Enable Cross region replication for the S3 bucket Submit yourFeedback/Queries to our Experts",
88,A Security Engineer must design a system that can detect whether a file on an Amazon EC2 host has been modified. The system must then alert the Security Engineer of the modification. What is the MOST efficient way to meet these requirements?,(A) Install antivirus software and ensure that signatures are up-to-date. Configure AmazonCloudWatch alarms to send alerts for security events.,(B) Install host-based IDS software to check for file integrity. Export the logs to Amazon CloudWatch Logs for monitoring and alerting.,(C) Export system log files to Amazon S3. Parse the log files using an AWS Lambda function that willsend alerts of any unauthorized system login attempts through Amazon SNS.,"(D) Use Amazon CloudWatch Logs to detect file system changes. If a change is detected, automaticallyterminate and recreate the instance from the most recent AMI. Use Amazon SNS to send notificationof the event.",B,,
91,"A Security Engineer launches two Amazon EC2 instances in the same Amazon VPC but in separate Availability Zones. Each instance has a public IP address and is able to connect to external hosts on the internet. The two instances are able to communicate with each other by using their private IP addresses, but they are not able to communicate with each other when using their public IP addresses. Which action should the Security Engineer take to allow communication over the public IP addresses?",(A) Associate the instances to the same security groups.,(B) Add 0.0.0.0/0 to the egress rules of the instance security groups.,(C) Add the instance IDs to the ingress rules of the instance security groups.,(D) Add the public IP addresses to the ingress rules of the instance security groups.,D,https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/security-group-rules-reference.html#sg-rules-other-ins,
92,"Example.com hosts its internal document repository on Amazon EC2 instances. Theapplication runs on EC2 instances and previously stored the documents on encrypted Amazon EBSvolumes. To optimize the application for scale, example.com has moved the files to Amazon S3. Thesecurity team has mandated that all the files are securely deleted from the EBS volume, and it mustcertify that the data is unreadable before releasing the underlying disks.Which of the following methods will ensure that the data is unreadable by anyone else?","(A) Change the volume encryption on the EBS volume to use a different encryption mechanism. Then,release the EBS volumes back to AWS.",(B) Release the volumes back to AWS. AWS immediately wipes the disk after it is deprovisioned.,"(C) Delete the encryption key used to encrypt the EBS volume. Then, release the EBS volumes back toAWS.",(D) Delete the data by using the operating system delete commands. Run Quick Format on the driveand then release the EBS volumes back to AWS.,D,"Amazon EBS volumes are presented to you as raw unformatted block devices that have been wipedprior to being made available for use. Wiping occurs immediately before reuse so that you can beassured that the wipe process completed. If you have procedures requiring that all data be wiped viaa specific method, such as those detailed in NIST 800-88 (""Guidelines for Media Sanitization""), youhave the ability to do so on Amazon EBS.You should conduct a specialized wipe procedure prior to deleting the volume for compliance with48your established requirements.https://d0.awsstatic.com/whitepapers/aws-security-whitepaper.pdf",
93,"Due to new compliance requirements, a Security Engineer must enable encryption withcustomer-provided keys on corporate data that is stored in DynamoDB. The company wants to retainfull control of the encryption keys.Which DynamoDB feature should the Engineer use to achieve compliance'?",(A) Use AWS Certificate Manager to request a certificate. Use that certificate to encrypt data prior touploading it to DynamoDB.,"(B) Enable S3 server-side encryption with the customer-provided keys. Upload the data to Amazon S3,and then use S3Copy to move all data to DynamoDB",(C) Create a KMS master key. Generate per-record data keys and use them to encrypt data prior touploading it to DynamoDS. Dispose of the cleartext and encrypted data keys after encryption withoutstoring.,(D) Use the DynamoDB Java encryption client to encrypt data prior to uploading it to DynamoDB.,D,Follow the link:https://docs.aws.amazon.com/dynamodb-encryption-client/latest/devguide/what-is-ddb-encrypt.html,
96,A company uses identity federation to authenticate users into an identity account(987654321987) where the users assume an IAM role named IdentityRole. The users then assume anIAM role named JobFunctionRole in the target AWS account (123456789123) to perform their jobfunctions.A user is unable to assume the IAM role in the target account. The policy attached to the role in theidentity account is:What should be done to enable the user to assume the appropriate role in the target account?5051,(A) Option A,(B) Option B,(C) Option C,(D) Option D,A,,
99,A company hosts data in S3. There is now a mandate that going forward all data in the S3 bucket needs to encrypt at rest. How can this be achieved? Please select:,(A) Use AWS Access keys to encrypt the data,(B) Use SSL certificates to encrypt the data,(C) Enable server side encryption on the S3 bucket,(D) Enable MFA on the S3 bucket,C,"The AWS Documentation mentions the followingServer-side encryption is about data encryption at rest-that is, Amazon S3 encrypts your data at theobject level as it writes it to disks in its data centers and decrypts it for you when you access it. Aslong as you authenticate your request and you have access permissions, there is no difference in theway you access encrypted or unencrypted objects.Options A and B are invalid because neither Access Keys nor SSL certificates can be used to encryptdata.Option D is invalid because MFA is just used as an extra level of security for S3 buckets For moreinformation on S3 server side encryption, please refer to the below Link:https://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html Submit yourFeedback/Queries to our Experts",
100,"A Systems Administrator has written the following Amazon S3 bucket policy designed to allow access to an S3 bucket for only an authorized AWS IAM user from the IP address range10.10.10.0/24. When trying to download an object from the S3 bucket from 10.10.10.40, the IAM user receives an access denied message. What does the Administrator need to change to grant access to the user?","(A) Change the ""Resource"" from ""arn: aws:s3:::Bucket"" to ""arn:aws:s3:::Bucket/*"".","(B) Change the ""Principal"" from ""*"" to {AWS:""arn:aws:iam: : account-number: user/username""}","(C) Change the ""Version"" from ""2012-10-17"" to the last revised date of the policy","(D) Change the ""Action"" from [""s3:*""] to [""s3:GetObject"", ""s3:ListBucket""]",A,,
101,Your company is planning on AWS on hosting its AWS resources. There is a company policy which mandates that all security keys are completely managed within the company itself. Which of the following is the correct measure of following this policy? Please select:,(A) Using the AWS KMS service for creation of the keys and the company managing the key lifecycle there after.,(B) Generating the key pairs for the EC2 Instances using puttygen,(C) Use the EC2 Key pairs that come with AWS,(D) Use S3 server-side encryption,B,"y ensuring that you generate the key pairs for EC2 Instances, you will have complete control of theaccess keys.Options A,C and D are invalid because all of these processes means that AWS has ownership of thekeys. And the question specifically mentions that you need ownership of the keys For information onsecurity for Compute Resources, please visit the below URL:https://d1.awsstatic.com/whitepapers/Security/Security Compute Services Whitepaper.pdfl Thecorrect answer is: Generating the key pairs for the EC2 Instances using puttygen Submit yourFeedback/Queries to our Experts",
104,Your company has a requirement to work with a DynamoDB table. There is a security mandate that all data should be encrypted at rest. What is the easiest way to accomplish this for DynamoDB. Please select:,(A) Use the AWS SDK to encrypt the data before sending it to the DynamoDB table,(B) Encrypt the DynamoDB table using KMS during its creation,(C) Encrypt the table using AWS KMS after it is created,(D) Use S3 buckets to encrypt the data before sending it to DynamoDB,B,"The most easiest option is to enable encryption when the DynamoDB table is created.The AWS Documentation mentions the following57Amazon DynamoDB offers fully managed encryption at rest. DynamoDB encryption at rest providesenhanced security by encrypting your data at rest using an AWS Key Management Service (AWS KMS)managed encryption key for DynamoDB. This functionality eliminates the operational burden andcomplexity involved in protecting sensitive data.Option A is partially correct, you can use the AWS SDK to encrypt the data, but the easier optionwould be to encrypt the table before hand.Option C is invalid because you cannot encrypt the table after it is created Option D is invalid becauseencryption for S3 buckets is for the objects in S3 only.For more information on securing data at rest for DynamoDB please refer to below URL:https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/EncryptionAtRest.htmll Thecorrect answer is: Encrypt the DynamoDB table using KMS during its creation Submit yourFeedback/Queries to our Experts",
105,An organization receives an alert that indicates that an EC2 instance behind an ELB ClassicLoad Balancer has been compromised.What techniques will limit lateral movement and allow evidence gathering?,(A) Remove the instance from the load balancer and terminate it.,"(B) Remove the instance from the load balancer, and shut down access to the instance by tighteningthe security group.",(C) Reboot the instance and check for any Amazon CloudWatch alarms.,(D) Stop the instance and make a snapshot of the root EBS volume.,B,https://d1.awsstatic.com/whitepapers/aws_security_incident_response.pdf,
106,A company uses user data scripts that contain sensitive information to bootstrap AmazonEC2 instances. A Security Engineer discovers that this sensitive information is viewable by people whoshould not have access to it.What is the MOST secure way to protect the sensitive information used to bootstrap the instances?,(A) Store the scripts in the AMI and encrypt the sensitive data using AWS KMS Use the instance roleprofile to control access to the KMS keys needed to decrypt the data.,(B) Store the sensitive data in AWS Systems Manager Parameter Store using the encrypted stringparameter and assign the GetParameters permission to the EC2 instance role.,(C) Externalize the bootstrap scripts in Amazon S3 and encrypt them using AWS KMS. Remove thescripts from the instance and clear the logs after the instance is configured.,(D) Block user access of the EC2 instance's metadata service using IAM policies. Remove all scripts andclear the logs after execution.,A,,
108,Your company is planning on hosting an internal network in AWS. They want machines inthe VPC to authenticate using private certificates. They want to minimize the work and maintenancein working with certificates. What is the ideal way to fulfil this requirement.Please select:,(A) Consider using Windows Server 2016 Certificate Manager,(B) Consider using AWS Certificate Manager,(C) Consider using AWS Access keys to generate the certificates,(D) Consider using AWS Trusted Advisor for managing the certificates,B,"The AWS Documentation mentions the followingACM is tightly linked with AWS Certificate Manager Private Certificate Authority. You can use ACMPCA to create a private certificate authority (CA) and then use ACM to issue private certificates. Theseare SSL/TLSX.509 certificates that identify users, computers, applications, services, servers, and other devicesinternally.Private certificates cannot be publicly trustedOption A is partially invalid. Windows Server 2016 Certificate Manager can be used but since there isa requirement to ""minimize the work and maintenance"", AWS Certificate Manager should be usedOption C and D are invalid because these cannot be used for managing certificates.For more information on ACM, please visit the below URL:https://docs.aws.amazon.com/acm/latest/userguide/acm-overview.htmlThe correct answer is: Consider using AWS Certificate Manager Submit your Feedback/Queries to ourExperts",
110,A user has created a VPC with the public and private subnets using the VPC wizard. The VPChas CIDR20.0.0.0/16. The public subnet uses CIDR 20.0.1.0/24. The user is planning to host a web server in thepublic subnet with port 80 and a Database server in the private subnet with port 3306. The user isconfiguring a security group for the public subnet (WebSecGrp) and the private subnet (DBSecGrp).which of the below mentioned entries is required in the private subnet database security groupDBSecGrp?Please select:,(A) Allow Inbound on port 3306 for Source Web Server Security Group WebSecGrp.,(B) Allow Inbound on port 3306 from source 20.0.0.0/16,(C) Allow Outbound on port 3306 for Destination Web Server Security Group WebSecGrp.60,(D) Allow Outbound on port 80 for Destination NAT Instance IP,A,Since the Web server needs to talk to the database server on port 3306 that means that the databaseserver should allow incoming traffic on port 3306. The below table from the aws documentationshows how the security groups should be set up.Option B is invalid because you need to allow incoming access for the database server from theWebSecGrp security group.Options C and D are invalid because you need to allow Outbound traffic and not inbound traffic Formore information on security groups please visit the below Link:http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPCScenario2.htmlThe correct answer is: Allow Inbound on port 3306 for Source Web Server Security GroupWebSecGrp.Submit your Feedback/Queries to our Experts,
111,Which of the following minimizes the potential attack surface for applications?,(A) Use security groups to provide stateful firewalls for Amazon EC2 instances at the hypervisor level.,(B) Use network ACLs to provide stateful firewalls at the VPC level to prevent access to any specificAWS resource.,(C) Use AWS Direct Connect for secure trusted connections between EC2 instances within privatesubnets.,"(D) Design network security in a single layer within the perimeter network (also known as DMZ,demilitarized zone, and screened subnet) to facilitate quicker responses to threats.",A,https://aws.amazon.com/answers/networking/vpc-security-capabilities/ Security Group is statefuland hypervisor level.,
112,"A company's database developer has just migrated an Amazon RDS database credential tobe stored and managed by AWS Secrets Manager. The developer has also enabled rotation of thecredential within the Secrets Manager console and set the rotation to change every 30 days.After a short period of time, a number of existing applications have failed with authentication errors.61What is the MOST likely cause of the authentication errors?",(A) Migrating the credential to RDS requires that all access come through requests to the SecretsManager.,"(B) Enabling rotation in Secrets Manager causes the secret to rotate immediately, and the applicationsare using the earlier credential.",(C) The Secrets Manager IAM policy does not allow access to the RDS database.,(D) The Secrets Manager IAM policy does not allow access for the applications.,B,https://docs.aws.amazon.com/secretsmanager/latest/userguide/enable-rotation-rds.html,
113,You are trying to use the AWS Systems Manager run command on a set of Instances. Therun command on a set of Instances. What can you do to diagnose the issue? Choose 2 answers fromthe options given Please select:,(A) Ensure that the SSM agent is running on the target machine,(B) Check the /var/log/amazon/ssm/errors.log file,(C) Ensure the right AMI is used for the Instance,(D) Ensure the security groups allow outbound communication for the instance,A B,"The AWS Documentation mentions the followingIf you experience problems executing commands using Run Command, there might be a problemwith the SSM Agent. Use the following information to help you troubleshoot the agent View AgentLogs The SSM Agent logs information in the following files. The information in these files can help youtroubleshoot problems.On Windows%PROGRAMDATA%\Amazon\SSM\Logs\amazon-ssm-agent.log%PROGRAMDATA%\Amazon\SSM\Logs\error.logThe default filename of the seelog is seelog-xml.template. If you modify a seelog, you must renamethe file to seelog.xml.On Linux/var/log/amazon/ssm/amazon-ssm-agentlog /var/log/amazon/ssm/errors.logOption C is invalid because the right AMI has nothing to do with the issues. The agent which is usedto execute run commands can run on a variety of AMI'S Option D is invalid because security groupsdoes not come into the picture with the communication between the agent and the SSM service Formore information on troubleshooting AWS SSM, please visit the following URL:https://docs.aws.amazon.com/systems-manaeer/latest/userguide/troubleshootine-remote-commands.htmll The correct answers are: Ensure that the SSM agent is running on the targetmachine. Check the/var/log/amazon/ssm/errors.log fileSubmit your Feedback/Queries to our Experts",
114,You have an S3 bucket hosted in AWS. This is used to host promotional videos uploaded byyourself. You need to provide access to users for a limited duration of time. How can this beachieved?62Please select:,(A) Use versioning and enable a timestamp for each version,(B) Use Pre-signed URL's,(C) Use 1AM Roles with a timestamp to limit the access,(D) Use 1AM policies with a timestamp to limit the access,B,"The AWS Documentation mentions the followingAll objects by default are private. Only the object owner has permission to access these objects.However, the object owner can optionally share objects with others by creating a pre-signed URLusing their own security credentials, to grant time-limited permission to download the objects.Option A is invalid because this can be used to prevent accidental deletion of objects Option C isinvalid because timestamps are not possible for Roles Option D is invalid because policies is not theright way to limit access based on time For more information on pre-signed URL's, please visit theURL:https://docs.aws.ama2on.com/AmazonS3/latest/dev/ShareObiectPreSisnedURL.html The correctanswer is: Use Pre-signed URL's Submit your Feedback/Queries to our Experts",
115,A Security Engineer must add additional protection to a legacy web application by addingthe following HTTP security headers:-Content Security-Policy-X-Frame-Options-X-XSS-ProtectionThe Engineer does not have access to the source code of the legacy web application.Which of the following approaches would meet this requirement?,(A) Configure an Amazon Route 53 routing policy to send all web traffic that does not include therequired headers to a black hole.,(B) Implement an AWS Lambda@Edge origin response function that inserts the required headers.,(C) Migrate the legacy application to an Amazon S3 static website and front it with an AmazonCloudFront distribution.,(D) Construct an AWS WAF rule to replace existing HTTP headers with the required security headersby using regular expressions.,B,,
116,A web application runs in a VPC on EC2 instances behind an ELB Application Load Balancer.The application stores data in an RDS MySQL DB instance. A Linux bastion host is used to applyschema updates to the database - administrators connect to the host via SSH from a corporateworkstation. The following security groups are applied to the infrastructure-* sgLB - associated with the ELB* sgWeb - associated with the EC2 instances.* sgDB - associated with the database* sgBastion - associated with the bastion host Which security group configuration will allow theapplication to be secure and functional?Please select:,(A) sgLB :allow port 80 and 443 traffic from 0.0.0.0/063sgWeb :allow port 80 and 443 traffic from 0.0.0.0/0sgDB :allow port 3306 traffic from sgWeb and sgBastionsgBastion: allow port 22 traffic from the corporate IP address range,(B) sgLB :aIlow port 80 and 443 traffic from 0.0.0.0/0sgWeb :allow port 80 and 443 traffic from sgLBsgDB :allow port 3306 traffic from sgWeb and sgLBsgBastion: allow port 22 traffic from the VPC IP address range,(C) sgLB :allow port 80 and 443 traffic from 0.0.0.0/0sgWeb :allow port 80 and 443 traffic from sgLBsgDB :allow port 3306 traffic from sgWeb and sgBastionsgBastion: allow port 22 traffic from the VPC IP address range,(D) sgLB :allow port 80 and 443 traffic from 0.0.0.0/0sgWeb :allow port 80 and 443 traffic from sgLBsgDB :al!ow port 3306 traffic from sgWeb and sgBastionsgBastion: allow port 22 traffic from the corporate IP address range,D,"The Load Balancer should accept traffic on ow port 80 and 443 traffic from 0.0.0.0/0 The backend EC2Instances should accept traffic from the Load Balancer The database should allow traffic from theWeb server And the Bastion host should only allow traffic from a specific corporate IP address rangeOption A is incorrect because the Web group should only allow traffic from the Load balancer Formore information on AWS Security Groups, please refer to below URL:https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/usins-network-security.htmll The correctanswer is: sgLB :allow port 80 and 443 traffic from 0.0.0.0/0 sgWeb :allow port 80 and 443 trafficfrom sgLB sgDB :allow port 3306 traffic from sgWeb and sgBastion sgBastion: allow port 22 trafficfrom the corporate IP address range Submit your Feedback/Queries to our Experts",
117,"An organization has three applications running on AWS, each accessing the same data onAmazon S3. The data on Amazon S3 is server-side encrypted by using an AWS KMS Customer MasterKey (CMK).What is the recommended method to ensure that each application has its own programmatic accesscontrol permissions on the KMS CMK?",(A) Change the key policy permissions associated with the KMS CMK for each application when it mustaccess the data in Amazon S3.,(B) Have each application assume an IAM role that provides permissions to use the AWS CertificateManager CMK.,(C) Have each application use a grant on the KMS CMK to add or remove specific access controls onthe KMS CMK.,(D) Have each application use an IAM policy in a user context to have specific access permissions onthe KMS CMK.,C,,
118,"A Security Engineer is setting up an AWS CloudTrail trail for all regions in an AWS account.For added security, the logs are stored using server-side encryption with AWS KMS-managed keys(SSE-KMS) and have log integrity validation enabled.64While testing the solution, the Security Engineer discovers that the digest files are readable, but thelog files are not. What is the MOST likely cause?",(A) The log files fail integrity validation and automatically are marked as unavailable.,(B) The KMS key policy does not grant the Security Engineer's IAM user or role permissions to decryptwith it.,(C) The bucket is set up to use server-side encryption with Amazon S3-managed keys (SSE-S3) as thedefault and does not allow SSE-KMS-encrypted files.,"(D) An IAM policy applicable to the Security Engineer's IAM user or role denies access to the""CloudTrail/"" prefix in the Amazon S3 bucket",B,,
119,A company is developing a highly resilient application to be hosted on multiple Amazon EC2instances . The application will store highly sensitive user data in Amazon RDS tables The applicationmust* Include migration to a different AWS Region in the application disaster recovery plan.* Provide a full audit trail of encryption key administration events* Allow only company administrators to administer keys.* Protect data at rest using application layer encryptionA Security Engineer is evaluating options for encryption key management Why should the SecurityEngineer choose AWS CloudHSM over AWS KMS for encryption key management in this situation?,(A) The key administration event logging generated by CloudHSM is significantly more extensive thanAWS KMS.,"(B) CloudHSM ensures that only company support staff can administer encryption keys, whereas AWSKMS allows AWS staff to administer keys",(C) The ciphertext produced by CloudHSM provides more robust protection against brute forcedecryption attacks than the ciphertext produced by AWS KMS,"(D) CloudHSM provides the ability to copy keys to a different Region, whereas AWS KMS does not",B,,
120,You are creating a Lambda function which will be triggered by a Cloudwatch Event. The datafrom these events needs to be stored in a DynamoDB table. How should the Lambda function begiven access to the DynamoDB table?Please select:,(A) Put the AWS Access keys in the Lambda function since the Lambda function by default is secure,(B) Use an 1AM role which has permissions to the DynamoDB table and attach it to the Lambdafunction.,(C) Use the AWS Access keys which has access to DynamoDB and then place it in an S3 bucket.,(D) Create a VPC endpoint for the DynamoDB table. Access the VPC endpoint from the Lambdafunction.,B,"AWS Lambda functions uses roles to interact with other AWS services. So use an 1AM role which haspermissions to the DynamoDB table and attach it to the Lambda function.Options A and C are all invalid because you should never use AWS keys for access.65Option D is invalid because the VPC endpoint is used for VPCsFor more information on Lambda function Permission model, please visit the URLhttps://docs.aws.amazon.com/lambda/latest/dg/intro-permission-model.html The correct answer is:Use an 1AM role which has permissions to the DynamoDB table and attach it to the Lambda function.Submit your Feedback/Queries to our Experts",
121,"You are deivising a policy to allow users to have the ability to access objects in a bucketcalled appbucket.You define the below custom bucket policy But when you try to apply the policy you get the error ""Action does not apply to any resource(s) instatement."" What should be done to rectify the error Please select:",(A) Change the 1AM permissions by applying PutBucketPolicy permissions.,(B) Verify that the policy has the same name as the bucket name. If not. make it the same.,"(C) Change the Resource section to ""arn:aws:s3:::appbucket/*'.","(D) Create the bucket ""appbucket"" and then apply the policy.",C,"When you define access to objects in a bucket you need to ensure that you specify to which objectsin the bucket access needs to be given to. In this case, the * can be used to assign the permission toall objects in the bucket Option A is invalid because the right permissions are already provided as perthe question requirement Option B is invalid because it is not necessary that the policy has the samename as the bucket Option D is invalid because this should be the default flow for applying the policy66For more information on bucket policies please visit the below URL:https://docs.aws.amazon.com/AmazonS3/latest/dev/example-bucket-policies.htmll The correctanswer is: Change the Resource section to ""arn:aws:s3:::appbucket/"" Submit your Feedback/Queriesto our Experts",
122,A security team is creating a response plan in the event an employee executes unauthorizedactions on AWS infrastructure. They want to include steps to determine if the employee's 1AMpermissions changed as part of the incident.What steps should the team document in the plan?Please select:,(A) Use AWS Config to examine the employee's 1AM permissions prior to the incident and comparethem to the employee's current 1AM permissions.,(B) Use Made to examine the employee's 1AM permissions prior to the incident and compare them tothe employee's A current 1AM permissions.,(C) Use CloudTrail to examine the employee's 1AM permissions prior to the incident and comparethem to the employee's current 1AM permissions.,(D) Use Trusted Advisor to examine the employee's 1AM permissions prior to the incident andcompare them to the employee's current 1AM permissions.,A,"You can use the AWSConfig history to see the history of a particular item.The below snapshot shows an example configuration for a user in AWS ConfigOption B,C and D are all invalid because these services cannot be used to see the history of aparticular configuration item. This can only be accomplished by AWS Config.For more information on tracking changes in AWS Config, please visit the below URL:https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/TrackineChanees.htmllThe correct answer is: Use AWS Config to examine the employee's 1AM permissions prior to theincident and compare them the employee's current 1AM permissions.Submit your Feedback/Queries to our Experts",
123,There is a set of Ec2 Instances in a private subnet. The application hosted on these EC2Instances need to access a DynamoDB table. It needs to be ensured that traffic does not flow out tothe internet. How can this be achieved?Please select:,(A) Use a VPC endpoint to the DynamoDB table,(B) Use a VPN connection from the VPC67,(C) Use a VPC gateway from the VPC,(D) Use a VPC Peering connection to the DynamoDB table,A,"The following diagram from the AWS Documentation shows how you can access the DynamoDBservice from within a V without going to the Internet This can be done with the help of a VPCendpointOption B is invalid because this is used for connection between an on-premise solution and AWSOption C is invalid because there is no such option Option D is invalid because this is used to connect2 VPCs For more information on VPC endpointsfor DynamoDB, please visit the URL:The correct answer is: Use a VPC endpoint to the DynamoDB table Submit your Feedback/Queries toour Experts",
124,"The Security Engineer is managing a web application that processes highly sensitive personalinformation. The application runs on Amazon EC2. The application has strict compliancerequirements, which instruct that all incoming traffic to the application is protected from commonweb exploits and that all outgoing traffic from the EC2 instances is restricted to specific whitelistedURLs.Which architecture should the Security Engineer use to meet these requirements?",(A) Use AWS Shield to scan inbound traffic for web exploits. Use VPC Flow Logs and AWS Lambda to68restrict egress traffic to specific whitelisted URLs.,(B) Use AWS Shield to scan inbound traffic for web exploits. Use a third-party AWS Marketplacesolution to restrict egress traffic to specific whitelisted URLs.,(C) Use AWS WAF to scan inbound traffic for web exploits. Use VPC Flow Logs and AWS Lambda torestrict egress traffic to specific whitelisted URLs.,(D) Use AWS WAF to scan inbound traffic for web exploits. Use a third-party AWS Marketplacesolution to restrict egress traffic to specific whitelisted URLs.,D,"AWS Shield is mainly for DDos Attacks.AWS WAF is mainly for some other types of attacks likeInjection and XSS etcIn this scenario, It seems it is WAF functionality that is needed.VPC logs do showthe source and destination IP and Port , they never show any URL .. because URL are level 7 whileVPC are concerned about lover network levels.https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html",
128,Your company has a set of EBS volumes defined in AWS. The security mandate is that all EBSvolumes are encrypted. What can be done to notify the IT admin staff if there are any unencryptedvolumes in the account.Please select:,(A) Use AWS Inspector to inspect all the EBS volumes,(B) Use AWS Config to check for unencrypted EBS volumes,(C) Use AWS Guard duty to check for the unencrypted EBS volumes,(D) Use AWS Lambda to check for the unencrypted EBS volumes,B,"The encconfig rule for AWS Config can be used to check for unencrypted volumes.70encrypted-volurrn5 volumes that are in an attached state are encrypted. If you specify the ID of a KMS key for encryptiousing the kmsld parameter, the rule checks if the EBS volumes in an attached state are encryptedwith that KMS key*1.Options A and C are incorrect since these services cannot be used to check for unencrypted EBSvolumes Option D is incorrect because even though this is possible, trying to implement the solutionalone with just the Lambda servk would be too difficult For more information on AWS Config andencrypted volumes, please refer to below URL:* https://docs.aws.amazon.com/config/latest/developerguide/encrypted-volumes.html Submit yourFeedback/Queries to our Experts",
129,"An auditor needs access to logs that record all API events on AWS. The auditor only needsread-only access to the log files and does not need access to each AWS account. The company hasmultiple AWS accounts, and the auditor needs access to all the logs for all the accounts. What is thebest way to configure access for the auditor to view event logs from all accounts? Choose the correctanswer from the options below Please select:","(A) Configure the CloudTrail service in each AWS account, and have the logs delivered to an AWSbucket on each account, while granting the auditor permissions to the bucket via roles in thesecondary accounts and a single primary 1AM account that can assume a read-only role in thesecondary AWS accounts.",(B) Configure the CloudTrail service in the primary AWS account and configure consolidated billing forall the secondary accounts. Then grant the auditor access to the S3 bucket that receives theCloudTrail log files.,(C) Configure the CloudTrail service in each AWS account and enable consolidated logging inside ofCloudTrail.,(D) Configure the CloudTrail service in each AWS account and have the logs delivered to a single AWSbucket in the primary account and erant the auditor access to that single bucket in the orimarvaccount.,D,"Given the current requirements, assume the method of ""least privilege"" security design and onlyallow the auditor access to the minimum amount of AWS resources as possibli AWS CloudTrail is aservice that enables governance, compliance, operational auditing, and risk auditing of your AWSaccount. With CloudTrail, you can log, continuously monitor, and retain events related to API callsacross your AWS infrastructure. CloudTrail provides a history of AWS API calls for your accountincluding API calls made through the AWS Management Console, AWS SDKs, command line tools, andother AWS services. This history simplifies security analysis, resource change tracking, andtroubleshooting only be granted access in one location Option Option A is incorrect since the auditorshould B is incorrect since consolidated billing is not a key requirement as part of the question OptionC is incorrect since there is not consolidated logging For more information on Cloudtrail please referto the below URL:https://aws.amazon.com/cloudtraiL(The correct answer is: Configure the CloudTrail service in each AWS account and have the logsdelivered to a single AWS bud in the primary account and grant the auditor access to that single71bucket in the primary account.Submit your Feedback/Queries to our Experts",
131,"You have been given a new brief from your supervisor for a client who needs a webapplication set up on AWS. The a most important requirement is that MySQL must be used as thedatabase, and this database must not be hosted in ts public cloud, but rather at the client's datacenter due to security risks. Which of the following solutions would be the ^ best to assure that theclient's requirements are met? Choose the correct answer from the options below Please select:",(A) Build the application server on a public subnet and the database at the client's data center.Connect them with a VPN connection which uses IPsec.,(B) Use the public subnet for the application server and use RDS with a storage gateway to access andsynchronize the data securely from the local data center.,(C) Build the application server on a public subnet and the database on a private subnet with a NATinstance between them.,(D) Build the application server on a public subnet and build the database in a private subnet with asecure ssh connection to the private subnet from the client's data center.,A,"Since the database should not be hosted on the cloud all other options are invalid.72The best option is to create a VPN connection for securing traffic as shown below.Option B is invalid because this is the incorrect use of the Storage gateway Option C is invalid sincethis is the incorrect use of the NAT instance Option D is invalid since this is an incorrect configurationFor more information on VPN connections, please visit the below URLhttp://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_VPN.htmllThe correct answer is: Build the application server on a public subnet and the database at the client'sdata center. Connect them with a VPN connection which uses IPsec Submit your Feedback/Queries toour Experts",
132,"When managing permissions for the API gateway, what can be used to ensure that the rightlevel of permissions are given to developers, IT admins and users? These permissions should be easilymanaged.Please select:",(A) Use the secure token service to manage the permissions for the different users,(B) Use 1AM Policies to create different policies for the different types of users.,(C) Use the AWS Config tool to manage the permissions for the different users,(D) Use 1AM Access Keys to create sets of keys for the different types of users.,B,"The AWS Documentation mentions the followingYou control access to Amazon API Gateway with 1AM permissions by controlling access to thefollowing two API Gateway component processes:* To create, deploy, and manage an API in API Gateway, you must grant the API developerpermissions to perform the required actions supported by the API management component of APIGateway.* To call a deployed API or to refresh the API caching, you must grant the API caller permissions toperform required 1AM actions supported by the API execution component of API Gateway.Option A, C and D are invalid because these cannot be used to control access to AWS services. This73needs to be done via policies. For more information on permissions with the API gateway, please visitthe following URL:https://docs.aws.amazon.com/apisateway/latest/developerguide/permissions.html The correctanswer is: Use 1AM Policies to create different policies for the different types of users. Submit yourFeedback/Queries to our Experts",
134,The InfoSec team has mandated that in the future only approved Amazon Machine Images(AMIs) can be used.How can the InfoSec team ensure compliance with this mandate?,(A) Terminate all Amazon EC2 instances and relaunch them with approved AMIs.,(B) Patch all running instances by using AWS Systems Manager.,(C) Deploy AWS Config rules and check all running instances for compliance.,(D) Define a metric filter in Amazon CloudWatch Logs to verify compliance.,C,https://docs.aws.amazon.com/config/latest/developerguide/approved-amis-by-id.html,
135,Your company has defined privileged users for their AWS Account. These users areadministrators for key resources defined in the company. There is now a mandate to enhance thesecurity authentication for these users. How can this be accomplished?Please select:74,(A) Enable MFA for these user accounts,(B) Enable versioning for these user accounts,(C) Enable accidental deletion for these user accounts,(D) Disable root access for the users,A,"The AWS Documentation mentions the following as a best practices for 1AM users. For extra security,enable multi-factor authentication (MFA) for privileged 1AM users (users who are allowed access tosensitive resources or APIs). With MFA, users have a device that generates unique authenticationcode (a one-time password, or OTP). Users must provide both their normal credentials (like their username and password) and the OTP. The MFA device can either be a special piece of hardware, or itcan be a virtual device (for example, it can run in an app on a smartphone).Option B,C and D are invalid because no such security options are available in AWS For moreinformation on1AM best practices, please visit the below URLhttps://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html The correct answer is:Enable MFA for these user accounts Submit your Feedback/Queries to our Experts",
136,Your company has mandated that all calls to the AWS KMS service be recorded. How canthis be achieved?Please select:,(A) Enable logging on the KMS service,(B) Enable a trail in Cloudtrail,(C) Enable Cloudwatch logs,(D) Use Cloudwatch metrics,B,"The AWS Documentation states the followingAWS KMS is integrated with CloudTrail, a service that captures API calls made by or on behalf of AWSKMS in your AWS account and delivers the log files to an Amazon S3 bucket that you specify.CloudTrail captures API calls from the AWS KMS console or from the AWS KMS API. Using theinformation collected by CloudTrail, you can determine what request was made, the source IPaddress from which the request was made, who made the request when it was made, and so on.Option A is invalid because logging is not possible in the KMS serviceOption C and D are invalid because Cloudwatch cannot be used to monitor API calls For moreinformation on logging using Cloudtrail please visit the below URLhttps://docs.aws.amazon.com/kms/latest/developerguide/loeeing-usine-cloudtrail.html The correctanswer is: Enable a trail in Cloudtrail Jubmit your Feedback/Queries to our Experts",
137,"In response to the past DDoS attack experiences, a Security Engineer has set up an AmazonCloudFront distribution for an Amazon S3 bucket. There is concern that some users may bypass theCloudFront distribution and access the S3 bucket directly.What must be done to prevent users from accessing the S3 objects directly by using URLs?",(A) Change the S3 bucket/object permission so that only the bucket owner has access.,"(B) Set up a CloudFront origin access identity (OAI), and change the S3 bucket/object permission so75that only the OAI has access.","(C) Create IAM roles for CloudFront, and change the S3 bucket/object permission so that only the IAMrole has access.",(D) Redirect S3 bucket access to the corresponding CloudFront distribution.,B,https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-restricting-access-to-s3,
138,A company is planning on using AWS EC2 and AWS Cloudfrontfor their web application. Forwhich one of the below attacks is usage of Cloudfront most suited for?Please select:,(A) Cross side scripting,(B) SQL injection,(C) DDoS attacks,(D) Malware attacks,C,"The below table from AWS shows the security capabilities of AWS Cloudfront AWS Cloudfront is moreprominent for DDoS attacks.Options A,B and D are invalid because Cloudfront is specifically used to protect sites against DDoSattacks For more information on security with Cloudfront, please refer to the below Link:https://d1.awsstatic.com/whitepapers/Security/Secure content delivery with CloudFrontwhitepaper.pdi The correct answer is: DDoS attacks Submit your Feedback/Queries to our Experts",
139,"A company is planning on using AWS for hosting their applications. They want completeseparation and isolation of their production , testing and development environments. Which of thefollowing is an ideal way to design such a setup?Please select:",(A) Use separate VPCs for each of the environments76,(B) Use separate 1AM Roles for each of the environments,(C) Use separate 1AM Policies for each of the environments,(D) Use separate AWS accounts for each of the environments,D,"A recommendation from the AWS Security Best practices highlights this as welloption A is partially valid, you can segregate resources, but a best practise is to have multipleaccounts for this setup.Options B and C are invalid because from a maintenance perspective this could become very difficultFor more information on the Security Best practices, please visit the following URL:https://dl.awsstatic.com/whitepapers/Security/AWS_Security_Best_Practices.pdf The correct answeris: Use separate AWS accounts for each of the environments Submit your Feedback/Queries to ourExperts",
140,You are responsible to deploying a critical application onto AWS. Part of the requirementsfor this application is to ensure that the controls set for this application met PCI compliance. Alsothere is a need to monitor web application logs to identify any malicious activity. Which of thefollowing services can be used to fulfil this requirement. Choose 2 answers from the options givenbelow Please select:,(A) Amazon Cloudwatch Logs,(B) Amazon VPC Flow Logs,(C) Amazon AWS Config,(D) Amazon Cloudtrail,A D,"The AWS Documentation mentions the following about these servicesAWS CloudTrail is a service that enables governance, compliance, operational auditing, and risk77auditing of your AWS account. With CloudTrail, you can log, continuously monitor, and retain accountactivity related to actions across your AWS infrastructure. CloudTrail provides event history of yourAWS account activity, including actions taken through the AWS Management Console, AWS SDKs,command line tools, and other AWS services. This event history simplifies security analysis, resourcechange tracking, and troubleshooting.Option B is incorrect because VPC flow logs can only check for flow to instances in a VPC Option C isincorrect because this can check for configuration changes only For more information on Cloudtrail,please refer to below URL:https://aws.amazon.com/cloudtrail;You can use Amazon CloudWatch Logs to monitor, store, and access your log files from AmazonElastic Compute Cloud (Amazon EC2) instances, AWS CloudTrail, Amazon Route 53, and othersources. You can then retrieve the associated log data from CloudWatch Logs.For more information on Cloudwatch logs, please refer to below URL:http://docs.aws.amazon.com/AmazonCloudWatch/latest/loes/WhatisCloudWatchLoES.htmll Thecorrect answers are: Amazon Cloudwatch Logs, Amazon Cloudtrail",
141,"A Developer's laptop was stolen. The laptop was not encrypted, and it contained the SSHkey used to access multiple Amazon EC2 instances. A Security Engineer has verified that the key hasnot been used, and has blocked port 22 to all EC2 instances while developing a response plan.How can the Security Engineer further protect currently running instances?","(A) Delete the key-pair key from the EC2 console, then create a new key pair.",(B) Use the modify-instance-attribute API to change the key on any EC2 instance that is using the key.,(C) Use the EC2 RunCommand to modify the authorized_keys file on any EC2 instance that is using thekey.,"(D) Update the key pair in any AMI used to launch the EC2 instances, then restart the EC2 instances.",C,,
142,A Security Engineer must design a solution that enables the Incident Response team to auditfor changes to a user's IAM permissions in the case of a security incident.How can this be accomplished?,(A) Use AWS Config to review the IAM policy assigned to users before and after the incident.,"(B) Run the GenerateCredentialReport via the AWS CLI, and copy the output to Amazon S3 daily forauditing purposes.","(C) Copy AWS CloudFormation templates to S3, and audit for changes from the template.","(D) Use Amazon EC2 Systems Manager to deploy images, and review AWS CloudTrail logs for changes.",A,https://aws.amazon.com/blogs/security/how-to-record-and-govern-your-iam-resource-configurations-using-aws-c,
143,"While analyzing a company's security solution, a Security Engineer wants to secure the AWSaccount root user.What should the Security Engineer do to provide the highest level of security for the account?",(A) Create a new IAM user that has administrator permissions in the AWS account. Delete thepassword for the AWS account root user.78,(B) Create a new IAM user that has administrator permissions in the AWS account. Modify thepermissions for the existing IAM users.,(C) Replace the access key for the AWS account root user. Delete the password for the AWS accountroot user.,(D) Create a new IAM user that has administrator permissions in the AWS account. Enable multi-factor authentication for the AWS account root user.,D,"If you continue to use the root user credentials, we recommend that you follow the security bestpractice to enable multi-factor authentication (MFA) for your account. Because your root user canperform sensitive operations in your account, adding an additional layer of authentication helps youto better secure your account. Multiple types of MFA are available.",
144,You have a vendor that needs access to an AWS resource. You create an AWS user account.You want to restrict access to the resource using a policy for just that user over a brief period. Whichof the following would be an ideal policy to use?Please select:,(A) An AWS Managed Policy,(B) An Inline Policy,(C) A Bucket Policy,(D) A bucket ACL,B,"The AWS Documentation gives an example on such a caseInline policies are useful if you want to maintain a strict one-to-one relationship between a policy andthe principal entity that if s applied to. For example, you want to be sure that the permissions in apolicy are not inadvertently assigned to a principal entity other than the one they're intended for.When you use an inline policy, the permissions in the policy cannot be inadvertently attached to thewrong principal entity. In addition, when you use the AWS Management Console to delete thatprincipal entit the policies embedded in the principal entity are deleted as well. That's because theyare part of the principal entity.Option A is invalid because AWS Managed Polices are ok for a group of users, but for individual users,inline policies are better.Option C and D are invalid because they are specifically meant for access to S3 buckets For moreinformation on policies, please visit the following URL:https://docs.aws.amazon.com/IAM/latest/UserGuide/access managed-vs-inline The correct answeris: An Inline Policy Submit your Feedback/Queries to our Experts",
146,Which option for the use of the AWS Key Management Service (KMS) supports keymanagement best practices that focus on minimizing the potential scope of data exposed by apossible future key compromise?,"(A) Use KMS automatic key rotation to replace the master key, and use this new master key for futureencryption operations without re-encrypting previously encrypted data.","(B) Generate a new Customer Master Key (CMK), re-encrypt all existing data with the new CMK, anduse it for all future encryption operations.","(C) Change the CMK alias every 90 days, and update key-calling applications with the new key alias.",(D) Change the CMK permissions to ensure that individuals who can provision keys are not the sameindividuals who can use the keys.,B,"""automatic key rotation has no effect on the data that the CMK protects. It does not rotate the datakeys that the CMK generated or re-encrypt any data protected by the CMK, and it will not mitigatethe effect of a compromised data key. You might decide to create a new CMK and use it in place ofthe original CMK. This has the same effect as rotating the key material in an existing CMK, so it'soften thought of as manually rotating the key.""https://docs.aws.amazon.com/kms/latest/developerguide/rotate-keys.html",
147,Your application currently uses customer keys which are generated via AWS KMS in the USeast region. You now want to use the same set of keys from the EU-Central region. How can this beaccomplished?Please select:,(A) Export the key from the US east region and import them into the EU-Central region,(B) Use key rotation and rotate the existing keys to the EU-Central region,(C) Use the backing key from the US east region and use it in the EU-Central region80,(D) This is not possible since keys from KMS are region specific,D,Option A is invalid because keys cannot be exported and imported across regions.Option B is invalid because key rotation cannot be used to export keysOption C is invalid because the backing key cannot be used to export keys This is mentioned in theAWS documentation What geographic region are my keys stored in?Keys are only stored and used in the region in which they are created. They cannot be transferred toanother region. For example; keys created in the EU-Central (Frankfurt) region are only stored andused within the EU-Central (Frankfurt) region For more information on KMS please visit the followingURL:https://aws.amazon.com/kms/faqs/The correct answer is: This is not possible since keys from KMS are region specific Submit yourFeedback/Queries to our Experts,
151,Your company has an external web site. This web site needs to access the objects in an S3bucket. Which of the following would allow the web site to access the objects in the most securemanner?Please select:,(A) Grant public access for the bucket via the bucket policy,(B) Use the aws:Referer key in the condition clause for the bucket policy,(C) Use the aws:sites key in the condition clause for the bucket policy,(D) Grant a role that can be assumed by the web site,B,"An example of this is given intheAWS DocumentatioiRestricting Access to a Specific HTTP ReferrerSuppose you have a website with domain name (www.example.com or example.com) with links tophotos and videos stored in your S3 bucket examplebucket. By default, all the S3 resources areprivate, so only the AWS account that created the resources can access them. To allow read access tothese objects from your website, you can add a bucket policy that allows s3:GetObject permissionwith a condition, using the aws:referer key, that the get request must originate from specificwebpages. The following policy specifies the StringLike condition with the aws:Referer condition key.82Option A is invalid because giving public access is not a secure way to provide access Option C isinvalid because aws:sites is not a valid condition key Option D is invalid because 1AM roles will not beassigned to web sites For more information on example bucket policies please visit the below Link:1 https://docs.aws.amazon.com/AmazonS3/latest/dev/example-bucket-policies.html The correctanswer is: Use the aws:Referer key in the condition clause for the bucket policy Submit yourFeedback/Queries to our Experts",
152,You work at a company that makes use of AWS resources. One of the key security policies isto ensure that all data i encrypted both at rest and in transit. Which of the following is one of theright ways to implement this.Please select:,(A) Use S3 SSE and use SSL for data in transit,(B) SSL termination on the ELB,(C) Enabling Proxy Protocol,(D) Enabling sticky sessions on your load balancer,A,"By disabling SSL termination, you are leaving an unsecure connection from the ELB to the back endinstances. Hence this means that part of the data transit is not being encrypted.83",